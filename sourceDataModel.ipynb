{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> SourceDataModel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> in database in tabel Sales_salesterritory attributt 'Group' veranderd naar 'Group1' vanwege error in code`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ODBC Driver 18 for SQL Server', 'ODBC Driver 17 for SQL Server']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import warnings\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "print(pyodbc.drivers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> inlezen database: AdventureWorks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV files: ['Sales_Store.csv', 'Production_BillOfMaterials.csv', 'Sales_SalesTerritory.csv', 'Person_Address.csv', 'Purchasing_Vendor.csv', 'Person_Person.csv', 'Purchasing_PurchaseOrderHeader.csv', 'Sales_SalesOrderDetail.csv', 'HumanResources_Employee.csv', 'Production_ProductCategory.csv', 'Production_Product.csv', 'HumanResources_Department.csv', 'Sales_SalesOrderHeader.csv', 'Purchasing_PurchaseOrderDetail.csv', 'Sales_Customer.csv']\n",
      "Loading file: databases/AdventureWorks/Sales_Store.csv\n",
      "Loading file: databases/AdventureWorks/Production_BillOfMaterials.csv\n",
      "Loading file: databases/AdventureWorks/Sales_SalesTerritory.csv\n",
      "Loading file: databases/AdventureWorks/Person_Address.csv\n",
      "Loading file: databases/AdventureWorks/Purchasing_Vendor.csv\n",
      "Loading file: databases/AdventureWorks/Person_Person.csv\n",
      "Loading file: databases/AdventureWorks/Purchasing_PurchaseOrderHeader.csv\n",
      "Loading file: databases/AdventureWorks/Sales_SalesOrderDetail.csv\n",
      "Loading file: databases/AdventureWorks/HumanResources_Employee.csv\n",
      "Loading file: databases/AdventureWorks/Production_ProductCategory.csv\n",
      "Loading file: databases/AdventureWorks/Production_Product.csv\n",
      "Loading file: databases/AdventureWorks/HumanResources_Department.csv\n",
      "Loading file: databases/AdventureWorks/Sales_SalesOrderHeader.csv\n",
      "Loading file: databases/AdventureWorks/Purchasing_PurchaseOrderDetail.csv\n",
      "Loading file: databases/AdventureWorks/Sales_Customer.csv\n",
      "Table: Sales_Store, Rows: 701\n",
      "   BusinessEntityID                            Name  SalesPersonID  \\\n",
      "0               292            Next-Door Bike Store            279   \n",
      "1               294  Professional Sales and Service            276   \n",
      "2               296                  Riders Company            277   \n",
      "3               298              The Bike Mechanics            275   \n",
      "4               300               Nationwide Supply            286   \n",
      "\n",
      "                                 rowguid       ModifiedDate  \n",
      "0  {A22517E3-848D-4EBE-B9D97437F3432304}  09/12/14 11:15:07  \n",
      "1  {B50CA50B-C601-4A13-B07E2C63862D71B4}  09/12/14 11:15:07  \n",
      "2  {337C3688-1339-4E1A-A08AB54B23566E49}  09/12/14 11:15:07  \n",
      "3  {7894F278-F0C8-4D16-BD75213FDBF13023}  09/12/14 11:15:07  \n",
      "4  {C3FC9705-A8C4-4F3A-9550EB2FA4B7B64D}  09/12/14 11:15:07  \n",
      "\n",
      "Columns: ['BusinessEntityID', 'Name', 'SalesPersonID', 'rowguid', 'ModifiedDate']\n",
      "Table: Production_BillOfMaterials, Rows: 2679\n",
      "   BillOfMaterialsID  ProductAssemblyID  ComponentID          StartDate  \\\n",
      "0                  1              807.0            1  03/04/20 00:00:00   \n",
      "1                  2              782.0          995  03/04/20 00:00:00   \n",
      "2                  3                NaN          989  03/04/20 00:00:00   \n",
      "3                  4                NaN          785  03/04/20 00:00:00   \n",
      "4                  5                NaN          775  03/04/20 00:00:00   \n",
      "\n",
      "  EndDate UnitMeasureCode  BOMLevel  PerAssemblyQty       ModifiedDate  \n",
      "0     NaN             EA          2             1.0  02/18/20 00:00:00  \n",
      "1     NaN             EA          1             1.0  02/18/20 00:00:00  \n",
      "2     NaN             EA          0             1.0  02/18/20 00:00:00  \n",
      "3     NaN             EA          0             1.0  02/18/20 00:00:00  \n",
      "4     NaN             EA          0             1.0  02/18/20 00:00:00  \n",
      "\n",
      "Columns: ['BillOfMaterialsID', 'ProductAssemblyID', 'ComponentID', 'StartDate', 'EndDate', 'UnitMeasureCode', 'BOMLevel', 'PerAssemblyQty', 'ModifiedDate']\n",
      "Table: Sales_SalesTerritory, Rows: 10\n",
      "   TerritoryID       Name CountryRegionCode          Group      SalesYTD  \\\n",
      "0            1  Northwest                US  North America  7.887187e+06   \n",
      "1            2  Northeast                US  North America  2.402177e+06   \n",
      "2            3    Central                US  North America  3.072175e+06   \n",
      "3            4  Southwest                US  North America  1.051085e+07   \n",
      "4            5  Southeast                US  North America  2.538667e+06   \n",
      "\n",
      "   SalesLastYear  CostYTD  CostLastYear  \\\n",
      "0   3.298694e+06      0.0           0.0   \n",
      "1   3.607149e+06      0.0           0.0   \n",
      "2   3.205014e+06      0.0           0.0   \n",
      "3   5.366576e+06      0.0           0.0   \n",
      "4   3.925071e+06      0.0           0.0   \n",
      "\n",
      "                                 rowguid       ModifiedDate  \n",
      "0  {43689A10-E30B-497F-B0DE11DE20267FF7}  04/30/08 00:00:00  \n",
      "1  {00FB7309-96CC-49E2-83630A1BA72486F2}  04/30/08 00:00:00  \n",
      "2  {DF6E7FD8-1A8D-468C-B103ED8ADDB452C1}  04/30/08 00:00:00  \n",
      "3  {DC3E9EA0-7950-4431-942899DBCBC33865}  04/30/08 00:00:00  \n",
      "4  {6DC4165A-5E4C-42D2-809D4344E0AC75E7}  04/30/08 00:00:00  \n",
      "\n",
      "Columns: ['TerritoryID', 'Name', 'CountryRegionCode', 'Group', 'SalesYTD', 'SalesLastYear', 'CostYTD', 'CostLastYear', 'rowguid', 'ModifiedDate']\n",
      "Table: Person_Address, Rows: 19614\n",
      "   AddressID          AddressLine1 AddressLine2     City  StateProvinceID  \\\n",
      "0          1         1970 Napa Ct.          NaN  Bothell               79   \n",
      "1          2    9833 Mt. Dias Blv.          NaN  Bothell               79   \n",
      "2          3  7484 Roundtree Drive          NaN  Bothell               79   \n",
      "3          4      9539 Glenside Dr          NaN  Bothell               79   \n",
      "4          5         1226 Shoe St.          NaN  Bothell               79   \n",
      "\n",
      "  PostalCode SpatialLocation                                rowguid  \\\n",
      "0      98011              æ\u0010  {9AADCB0D-36CF-483F-84D8585C2D4EC6E9}   \n",
      "1      98011              æ\u0010  {32A54B9E-E034-4BFB-B573A71CDE60D8C0}   \n",
      "2      98011              æ\u0010  {4C506923-6D1B-452C-A07CBAA6F5B142A4}   \n",
      "3      98011              æ\u0010  {E5946C78-4BCC-477F-9FA1CC09DE16A880}   \n",
      "4      98011              æ\u0010  {FBAFF937-4A97-4AF0-81FDB849900E9BB0}   \n",
      "\n",
      "        ModifiedDate  BusinessEntityID  \n",
      "0  12/04/17 00:00:00                12  \n",
      "1  11/30/18 00:00:00               123  \n",
      "2  03/07/23 00:00:00               285  \n",
      "3  02/03/19 00:00:00               251  \n",
      "4  12/19/18 00:00:00               124  \n",
      "\n",
      "Columns: ['AddressID', 'AddressLine1', 'AddressLine2', 'City', 'StateProvinceID', 'PostalCode', 'SpatialLocation', 'rowguid', 'ModifiedDate', 'BusinessEntityID']\n",
      "Table: Purchasing_Vendor, Rows: 104\n",
      "   BusinessEntityID AccountNumber                     Name  CreditRating  \\\n",
      "0              1492  AUSTRALI0001  Australia Bike Retailer             1   \n",
      "1              1494  ALLENSON0001          Allenson Cycles             2   \n",
      "2              1496  ADVANCED0001        Advanced Bicycles             1   \n",
      "3              1498    TRIKES0001             Trikes, Inc.             2   \n",
      "4              1500   MORGANB0001  Morgan Bike Accessories             1   \n",
      "\n",
      "   PreferredVendorStatus  ActiveFlag PurchasingWebServiceURL  \\\n",
      "0                     -1          -1                     NaN   \n",
      "1                     -1          -1                     NaN   \n",
      "2                     -1          -1                     NaN   \n",
      "3                     -1          -1                     NaN   \n",
      "4                     -1          -1                     NaN   \n",
      "\n",
      "        ModifiedDate  \n",
      "0  12/23/21 00:00:00  \n",
      "1  04/25/21 00:00:00  \n",
      "2  04/25/21 00:00:00  \n",
      "3  02/03/22 00:00:00  \n",
      "4  02/02/22 00:00:00  \n",
      "\n",
      "Columns: ['BusinessEntityID', 'AccountNumber', 'Name', 'CreditRating', 'PreferredVendorStatus', 'ActiveFlag', 'PurchasingWebServiceURL', 'ModifiedDate']\n",
      "Table: Person_Person, Rows: 19972\n",
      "   BusinessEntityID PersonType  NameStyle Title FirstName MiddleName  \\\n",
      "0                 1         EM          0   NaN       Ken          J   \n",
      "1                 2         EM          0   NaN     Terri        Lee   \n",
      "2                 3         EM          0   NaN   Roberto        NaN   \n",
      "3                 4         EM          0   NaN       Rob        NaN   \n",
      "4                 5         EM          0   Ms.      Gail          A   \n",
      "\n",
      "     LastName Suffix  EmailPromotion                                rowguid  \\\n",
      "0    SÃ¡nchez    NaN               0  {92C4279F-1207-48A3-84484636514EB7E2}   \n",
      "1       Duffy    NaN               1  {D8763459-8AA8-47CC-AFF7C9079AF79033}   \n",
      "2  Tamburello    NaN               0  {E1A2555E-0828-434B-A33B6F38136A37DE}   \n",
      "3     Walters    NaN               0  {F2D7CE06-38B3-4357-805BF4B6B71C01FF}   \n",
      "4    Erickson    NaN               0  {F3A3F6B4-AE3B-430C-A7549F2231BA6FEF}   \n",
      "\n",
      "        ModifiedDate  \n",
      "0  01/07/19 00:00:00  \n",
      "1  01/24/18 00:00:00  \n",
      "2  11/04/17 00:00:00  \n",
      "3  11/28/17 00:00:00  \n",
      "4  12/30/17 00:00:00  \n",
      "\n",
      "Columns: ['BusinessEntityID', 'PersonType', 'NameStyle', 'Title', 'FirstName', 'MiddleName', 'LastName', 'Suffix', 'EmailPromotion', 'rowguid', 'ModifiedDate']\n",
      "Table: Purchasing_PurchaseOrderHeader, Rows: 4012\n",
      "   PurchaseOrderID  RevisionNumber  Status  EmployeeID  VendorID  \\\n",
      "0                1               4       4         258      1580   \n",
      "1                2               4       1         254      1496   \n",
      "2                3               4       4         257      1494   \n",
      "3                4               4       3         261      1650   \n",
      "4                5               4       4         251      1654   \n",
      "\n",
      "   ShipMethodID          OrderDate           ShipDate    SubTotal     TaxAmt  \\\n",
      "0             3  04/16/21 00:00:00  04/25/21 00:00:00    201.0400    16.0832   \n",
      "1             5  04/16/21 00:00:00  04/25/21 00:00:00    272.1015    21.7681   \n",
      "2             2  04/16/21 00:00:00  04/25/21 00:00:00   8847.3000   707.7840   \n",
      "3             5  04/16/21 00:00:00  04/25/21 00:00:00    171.0765    13.6861   \n",
      "4             4  04/30/21 00:00:00  05/09/21 00:00:00  20397.3000  1631.7840   \n",
      "\n",
      "    Freight    TotalDue       ModifiedDate  \n",
      "0    5.0260    222.1492  04/25/21 00:00:00  \n",
      "1    6.8025    300.6721  04/25/21 00:00:00  \n",
      "2  221.1825   9776.2665  04/25/21 00:00:00  \n",
      "3    4.2769    189.0395  04/25/21 00:00:00  \n",
      "4  509.9325  22539.0165  05/09/21 00:00:00  \n",
      "\n",
      "Columns: ['PurchaseOrderID', 'RevisionNumber', 'Status', 'EmployeeID', 'VendorID', 'ShipMethodID', 'OrderDate', 'ShipDate', 'SubTotal', 'TaxAmt', 'Freight', 'TotalDue', 'ModifiedDate']\n",
      "Table: Sales_SalesOrderDetail, Rows: 121317\n",
      "   SalesOrderID  SalesOrderDetailID CarrierTrackingNumber  OrderQty  \\\n",
      "0         43659                   1          4911-403C-98         1   \n",
      "1         43659                   2          4911-403C-98         3   \n",
      "2         43659                   3          4911-403C-98         1   \n",
      "3         43659                   4          4911-403C-98         1   \n",
      "4         43659                   5          4911-403C-98         1   \n",
      "\n",
      "   ProductID  SpecialOfferID  UnitPrice  UnitPriceDiscount  LineTotal  \\\n",
      "0        776               1   2024.994                0.0   2024.994   \n",
      "1        777               1   2024.994                0.0   6074.982   \n",
      "2        778               1   2024.994                0.0   2024.994   \n",
      "3        771               1   2039.994                0.0   2039.994   \n",
      "4        772               1   2039.994                0.0   2039.994   \n",
      "\n",
      "                                 rowguid       ModifiedDate  \n",
      "0  {B207C96D-D9E6-402B-84702CC176C42283}  05/31/21 00:00:00  \n",
      "1  {7ABB600D-1E77-41BE-9FE5B9142CFC08FA}  05/31/21 00:00:00  \n",
      "2  {475CF8C6-49F6-486E-B0ADAFC6A50CDD2F}  05/31/21 00:00:00  \n",
      "3  {04C4DE91-5815-45D6-8670F462719FBCE3}  05/31/21 00:00:00  \n",
      "4  {5A74C7D2-E641-438E-A7AC37BF23280301}  05/31/21 00:00:00  \n",
      "\n",
      "Columns: ['SalesOrderID', 'SalesOrderDetailID', 'CarrierTrackingNumber', 'OrderQty', 'ProductID', 'SpecialOfferID', 'UnitPrice', 'UnitPriceDiscount', 'LineTotal', 'rowguid', 'ModifiedDate']\n",
      "Table: HumanResources_Employee, Rows: 290\n",
      "   BusinessEntityID  NationalIDNumber                   LoginID  \\\n",
      "0                 1         295847284      adventure-works\\ken0   \n",
      "1                 2         245797967    adventure-works\\terri0   \n",
      "2                 3         509647174  adventure-works\\roberto0   \n",
      "3                 4         112457891      adventure-works\\rob0   \n",
      "4                 5         695256908     adventure-works\\gail0   \n",
      "\n",
      "  OrganizationNode  OrganizationLevel                       JobTitle  \\\n",
      "0              NaN                NaN        Chief Executive Officer   \n",
      "1                X                1.0  Vice President of Engineering   \n",
      "2               ZÀ                2.0            Engineering Manager   \n",
      "3               ZÖ                3.0           Senior Tool Designer   \n",
      "4               ZÚ                3.0                Design Engineer   \n",
      "\n",
      "    BirthDate MaritalStatus Gender    HireDate  SalariedFlag  VacationHours  \\\n",
      "0  1979-01-29             S      M  2019-01-14            -1             99   \n",
      "1  1981-08-01             S      F  2018-01-31            -1              1   \n",
      "2  1984-11-12             M      M  2017-11-11            -1              2   \n",
      "3  1984-12-23             S      M  2017-12-05             0             48   \n",
      "4  1962-09-27             M      F  2018-01-06            -1              5   \n",
      "\n",
      "   SickLeaveHours  CurrentFlag                                rowguid  \\\n",
      "0              69           -1  {F01251E5-96A3-448D-981E0F99D789110D}   \n",
      "1              20           -1  {45E8F437-670D-4409-93CBF9424A40D6EE}   \n",
      "2              21           -1  {9BBBFB2C-EFBB-4217-9AB7F97689328841}   \n",
      "3              80           -1  {59747955-87B8-443F-8ED4F8AD3AFDF3A9}   \n",
      "4              22           -1  {EC84AE09-F9B8-4A15-B4A96CCBAB919B08}   \n",
      "\n",
      "        ModifiedDate  DepartmentID  \n",
      "0  06/30/24 00:00:00            16  \n",
      "1  06/30/24 00:00:00             1  \n",
      "2  06/30/24 00:00:00             1  \n",
      "3  06/30/24 00:00:00             2  \n",
      "4  06/30/24 00:00:00             1  \n",
      "\n",
      "Columns: ['BusinessEntityID', 'NationalIDNumber', 'LoginID', 'OrganizationNode', 'OrganizationLevel', 'JobTitle', 'BirthDate', 'MaritalStatus', 'Gender', 'HireDate', 'SalariedFlag', 'VacationHours', 'SickLeaveHours', 'CurrentFlag', 'rowguid', 'ModifiedDate', 'DepartmentID']\n",
      "Table: Production_ProductCategory, Rows: 4\n",
      "   ProductCategoryID         Name                                rowguid  \\\n",
      "0                  1        Bikes  {CFBDA25C-DF71-47A7-B81B64EE161AA37C}   \n",
      "1                  2   Components  {C657828D-D808-4ABA-91A3AF2CE02300E9}   \n",
      "2                  3     Clothing  {10A7C342-CA82-48D4-8A3846A2EB089B74}   \n",
      "3                  4  Accessories  {2BE3BE36-D9A2-4EEE-B593ED895D97C2A6}   \n",
      "\n",
      "        ModifiedDate  \n",
      "0  04/30/18 00:00:00  \n",
      "1  04/30/18 00:00:00  \n",
      "2  04/30/18 00:00:00  \n",
      "3  04/30/18 00:00:00  \n",
      "\n",
      "Columns: ['ProductCategoryID', 'Name', 'rowguid', 'ModifiedDate']\n",
      "Table: Production_Product, Rows: 504\n",
      "   ProductID                   Name ProductNumber  MakeFlag  \\\n",
      "0          1        Adjustable Race       AR-5381         0   \n",
      "1          2           Bearing Ball       BA-8327         0   \n",
      "2          3        BB Ball Bearing       BE-2349        -1   \n",
      "3          4  Headset Ball Bearings       BE-2908         0   \n",
      "4        316                  Blade       BL-2036        -1   \n",
      "\n",
      "   FinishedGoodsFlag Color  SafetyStockLevel  ReorderPoint  StandardCost  \\\n",
      "0                  0   NaN              1000           750           0.0   \n",
      "1                  0   NaN              1000           750           0.0   \n",
      "2                  0   NaN               800           600           0.0   \n",
      "3                  0   NaN               800           600           0.0   \n",
      "4                  0   NaN               800           600           0.0   \n",
      "\n",
      "   ListPrice  ... Class Style ProductSubcategoryID  ProductModelID  \\\n",
      "0        0.0  ...   NaN   NaN                  NaN             NaN   \n",
      "1        0.0  ...   NaN   NaN                  NaN             NaN   \n",
      "2        0.0  ...   NaN   NaN                  NaN             NaN   \n",
      "3        0.0  ...   NaN   NaN                  NaN             NaN   \n",
      "4        0.0  ...   NaN   NaN                  NaN             NaN   \n",
      "\n",
      "       SellStartDate SellEndDate DiscontinuedDate  \\\n",
      "0  04/30/18 00:00:00         NaN              NaN   \n",
      "1  04/30/18 00:00:00         NaN              NaN   \n",
      "2  04/30/18 00:00:00         NaN              NaN   \n",
      "3  04/30/18 00:00:00         NaN              NaN   \n",
      "4  04/30/18 00:00:00         NaN              NaN   \n",
      "\n",
      "                                 rowguid       ModifiedDate  ProductCategoryID  \n",
      "0  {694215B7-08F7-4C0D-ACB1D734BA44C0C8}  02/08/24 10:01:37                NaN  \n",
      "1  {58AE3C20-4F3A-4749-A7D4D568806CC537}  02/08/24 10:01:37                NaN  \n",
      "2  {9C21AED2-5BFA-4F18-BCB8F11638DC2E4E}  02/08/24 10:01:37                NaN  \n",
      "3  {ECFED6CB-51FF-49B5-B06C7D8AC834DB8B}  02/08/24 10:01:37                NaN  \n",
      "4  {E73E9750-603B-4131-89F53DD15ED5FF80}  02/08/24 10:01:37                NaN  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "Columns: ['ProductID', 'Name', 'ProductNumber', 'MakeFlag', 'FinishedGoodsFlag', 'Color', 'SafetyStockLevel', 'ReorderPoint', 'StandardCost', 'ListPrice', 'Size', 'SizeUnitMeasureCode', 'WeightUnitMeasureCode', 'Weight', 'DaysToManufacture', 'ProductLine', 'Class', 'Style', 'ProductSubcategoryID', 'ProductModelID', 'SellStartDate', 'SellEndDate', 'DiscontinuedDate', 'rowguid', 'ModifiedDate', 'ProductCategoryID']\n",
      "Table: HumanResources_Department, Rows: 16\n",
      "   DepartmentID         Name                 GroupName       ModifiedDate\n",
      "0             1  Engineering  Research and Development  04/30/18 00:00:00\n",
      "1             2  Tool Design  Research and Development  04/30/18 00:00:00\n",
      "2             3        Sales       Sales and Marketing  04/30/18 00:00:00\n",
      "3             4    Marketing       Sales and Marketing  04/30/18 00:00:00\n",
      "4             5   Purchasing      Inventory Management  04/30/18 00:00:00\n",
      "\n",
      "Columns: ['DepartmentID', 'Name', 'GroupName', 'ModifiedDate']\n",
      "Table: Sales_SalesOrderHeader, Rows: 31465\n",
      "   SalesOrderID  RevisionNumber          OrderDate            DueDate  \\\n",
      "0         43659               8  05/31/21 00:00:00  06/12/21 00:00:00   \n",
      "1         43660               8  05/31/21 00:00:00  06/12/21 00:00:00   \n",
      "2         43661               8  05/31/21 00:00:00  06/12/21 00:00:00   \n",
      "3         43662               8  05/31/21 00:00:00  06/12/21 00:00:00   \n",
      "4         43663               8  05/31/21 00:00:00  06/12/21 00:00:00   \n",
      "\n",
      "            ShipDate  Status  OnlineOrderFlag SalesOrderNumber  \\\n",
      "0  06/07/21 00:00:00       5                0          SO43659   \n",
      "1  06/07/21 00:00:00       5                0          SO43660   \n",
      "2  06/07/21 00:00:00       5                0          SO43661   \n",
      "3  06/07/21 00:00:00       5                0          SO43662   \n",
      "4  06/07/21 00:00:00       5                0          SO43663   \n",
      "\n",
      "  PurchaseOrderNumber   AccountNumber  ...  CreditCardID  \\\n",
      "0         PO522145787  10-4020-000676  ...       16281.0   \n",
      "1       PO18850127500  10-4020-000117  ...        5618.0   \n",
      "2       PO18473189620  10-4020-000442  ...        1346.0   \n",
      "3       PO18444174044  10-4020-000227  ...       10456.0   \n",
      "4       PO18009186470  10-4020-000510  ...        4322.0   \n",
      "\n",
      "   CreditCardApprovalCode  CurrencyRateID    SubTotal     TaxAmt   Freight  \\\n",
      "0           105041Vi84182             NaN  20565.6206  1971.5149  616.0984   \n",
      "1           115213Vi29411             NaN   1294.2529   124.2483   38.8276   \n",
      "2             85274Vi6854             4.0  32726.4786  3153.7696  985.5530   \n",
      "3           125295Vi53935             4.0  28832.5289  2775.1646  867.2389   \n",
      "4            45303Vi22691             NaN    419.4589    40.2681   12.5838   \n",
      "\n",
      "     TotalDue Comment                                rowguid  \\\n",
      "0  23153.2339     NaN  {79B65321-39CA-4115-9CBA8FE0903E12E6}   \n",
      "1   1457.3288     NaN  {738DC42D-D03B-48A1-9822F95A67EA7389}   \n",
      "2  36865.8012     NaN  {D91B9131-18A4-4A11-BC3A90B6F53E9D74}   \n",
      "3  32474.9324     NaN  {4A1ECFC0-CC3A-4740-B0281C50BB48711C}   \n",
      "4    472.3108     NaN  {9B1E7A40-6AE0-4AD3-811CA64951857C4B}   \n",
      "\n",
      "        ModifiedDate  \n",
      "0  06/07/21 00:00:00  \n",
      "1  06/07/21 00:00:00  \n",
      "2  06/07/21 00:00:00  \n",
      "3  06/07/21 00:00:00  \n",
      "4  06/07/21 00:00:00  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "Columns: ['SalesOrderID', 'RevisionNumber', 'OrderDate', 'DueDate', 'ShipDate', 'Status', 'OnlineOrderFlag', 'SalesOrderNumber', 'PurchaseOrderNumber', 'AccountNumber', 'CustomerID', 'SalesPersonID', 'TerritoryID', 'BillToAddressID', 'ShipToAddressID', 'ShipMethodID', 'CreditCardID', 'CreditCardApprovalCode', 'CurrencyRateID', 'SubTotal', 'TaxAmt', 'Freight', 'TotalDue', 'Comment', 'rowguid', 'ModifiedDate']\n",
      "Table: Purchasing_PurchaseOrderDetail, Rows: 8845\n",
      "   PurchaseOrderID  PurchaseOrderDetailID            DueDate  OrderQty  \\\n",
      "0                1                      1  04/30/21 00:00:00         4   \n",
      "1                2                      2  04/30/21 00:00:00         3   \n",
      "2                2                      3  04/30/21 00:00:00         3   \n",
      "3                3                      4  04/30/21 00:00:00       550   \n",
      "4                4                      5  04/30/21 00:00:00         3   \n",
      "\n",
      "   ProductID  UnitPrice  LineTotal  ReceivedQty  RejectedQty  StockedQty  \\\n",
      "0          1    50.2600   201.0400          3.0          0.0         3.0   \n",
      "1        359    45.1200   135.3600          3.0          0.0         3.0   \n",
      "2        360    45.5805   136.7415          3.0          0.0         3.0   \n",
      "3        530    16.0860  8847.3000        550.0          0.0       550.0   \n",
      "4          4    57.0255   171.0765          2.0          1.0         1.0   \n",
      "\n",
      "        ModifiedDate  \n",
      "0  04/23/21 00:00:00  \n",
      "1  04/23/21 00:00:00  \n",
      "2  04/23/21 00:00:00  \n",
      "3  04/23/21 00:00:00  \n",
      "4  04/23/21 00:00:00  \n",
      "\n",
      "Columns: ['PurchaseOrderID', 'PurchaseOrderDetailID', 'DueDate', 'OrderQty', 'ProductID', 'UnitPrice', 'LineTotal', 'ReceivedQty', 'RejectedQty', 'StockedQty', 'ModifiedDate']\n",
      "Table: Sales_Customer, Rows: 19820\n",
      "   CustomerID  PersonID  StoreID  TerritoryID AccountNumber  \\\n",
      "0           1       NaN    934.0            1    AW00000001   \n",
      "1           2       NaN   1028.0            1    AW00000002   \n",
      "2           3       NaN    642.0            4    AW00000003   \n",
      "3           4       NaN    932.0            4    AW00000004   \n",
      "4           5       NaN   1026.0            4    AW00000005   \n",
      "\n",
      "                                 rowguid       ModifiedDate  \n",
      "0  {3F5AE95E-B87D-4AED-95B4C3797AFCB74F}  09/12/24 11:15:07  \n",
      "1  {E552F657-A9AF-4A7D-A645C429D6E02491}  09/12/24 11:15:07  \n",
      "2  {130774B1-DB21-4EF3-98C8C104BCD6ED6D}  09/12/24 11:15:07  \n",
      "3  {FF862851-1DAA-4044-BE7C3E85583C054D}  09/12/24 11:15:07  \n",
      "4  {83905BDC-6F5E-4F71-B162C98DA069F38A}  09/12/24 11:15:07  \n",
      "\n",
      "Columns: ['CustomerID', 'PersonID', 'StoreID', 'TerritoryID', 'AccountNumber', 'rowguid', 'ModifiedDate']\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing the CSV files\n",
    "csv_folder = \"databases/AdventureWorks\"\n",
    "\n",
    "# List all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "print(f\"Found CSV files: {csv_files}\")\n",
    "\n",
    "# Initialize a dictionary to store DataFrames\n",
    "df_AdventureWorks = {}\n",
    "\n",
    "# Loop through each CSV file and load it into a DataFrame\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(csv_folder, csv_file)\n",
    "    print(f\"Loading file: {file_path}\")\n",
    "    try:\n",
    "        # Try reading the file with a fallback encoding\n",
    "        df = pd.read_csv(file_path, encoding='latin1')  # Use 'latin1' or 'iso-8859-1' if UTF-8 fails\n",
    "        # Store the DataFrame in the dictionary with the table name as the key\n",
    "        table_name = os.path.splitext(csv_file)[0]\n",
    "        df_AdventureWorks[table_name] = df\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {csv_file}: {e}\")\n",
    "\n",
    "# Access individual DataFrames by their table name\n",
    "for table_name, df in df_AdventureWorks.items():\n",
    "    print(f\"Table: {table_name}, Rows: {len(df)}\\n{df.head()}\\n\")\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "\n",
    "#function to clean nan values\n",
    "def clean_nan_values(dw):\n",
    "    for table_name, df in dw.items():\n",
    "        # Zet alle NaN naar None zodat SQL Server NULL kan verwerken\n",
    "        dw[table_name] = df.astype(object).where(pd.notnull(df), None)\n",
    "    return dw\n",
    "\n",
    "# Clean NaN values\n",
    "df_AdventureWorks = clean_nan_values(df_AdventureWorks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> inlezen database: aenc.sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found tables: ['Department', 'Product', 'State', 'Bonus', 'Customer', 'Employee', 'Sales_Order', 'Sales_Order_Item']\n",
      "Loading table: Department\n",
      "Loading table: Product\n",
      "Loading table: State\n",
      "Loading table: Bonus\n",
      "Loading table: Customer\n",
      "Loading table: Employee\n",
      "Loading table: Sales_Order\n",
      "Loading table: Sales_Order_Item\n",
      "Table: Department, Rows: 5\n",
      "   dept_id  dept_name  dept_head_id\n",
      "0      100      R & D           501\n",
      "1      200      Sales           902\n",
      "2      300    Finance          1293\n",
      "3      400  Marketing          1576\n",
      "4      500   Shipping           703\n",
      "\n",
      "Table: Product, Rows: 10\n",
      "    id          name description          prod_size   color  quantity  \\\n",
      "0  300     Tee Shirt    Tank Top              Small   White        18   \n",
      "1  301     Tee Shirt      V-neck             Medium  Orange        39   \n",
      "2  302     Tee Shirt   Crew Neck  One size fits all   Black        72   \n",
      "3  400  Baseball Cap  Cotton Cap  One size fits all   Black        92   \n",
      "4  401  Baseball Cap    Wool cap  One size fits all   White        12   \n",
      "\n",
      "   unit_price picture_name     Category  \n",
      "0           9  tshirtw.bmp      Clothes  \n",
      "1          14  tshirto.bmp      Clothes  \n",
      "2          14  tshirtb.bmp      Clothes  \n",
      "3           9     capb.bmp  Accessories  \n",
      "4          10     capw.bmp  Accessories  \n",
      "\n",
      "Table: State, Rows: 63\n",
      "  state_id state_name state_capital country   region\n",
      "0       AB    Alberta      Edmonton     CAN   Canada\n",
      "1       AK     Alaska        Juneau     USA  Western\n",
      "2       AL    Alabama    Montgomery     USA    South\n",
      "3       AR   Arkansas   Little Rock     USA    South\n",
      "4       AZ    Arizona       Phoenix     USA  Western\n",
      "\n",
      "Table: Bonus, Rows: 37\n",
      "   emp_id bonus_date  bonus_amount\n",
      "0     129  31-dec-24            50\n",
      "1     195  31-dec-23            50\n",
      "2     299  31-dec-23           200\n",
      "3    1142  31-dec-23           100\n",
      "4     129  31-dec-22            50\n",
      "\n",
      "Table: Customer, Rows: 126\n",
      "    id     fname         lname                 address        city state  \\\n",
      "0  101  Michaels        Devlin     3114 Pioneer Avenue  Rutherford    NJ   \n",
      "1  102      Beth        Reiser      1033 Whippany Road    New York    NY   \n",
      "2  103      Erin  Niedringhaus     1990 Windsor Street       Paoli    PA   \n",
      "3  104    Meghan         Mason  550 Dundas Street East   Knoxville    TN   \n",
      "4  105     Laura      McCarthy         1210 Highway 36      Carmel    IN   \n",
      "\n",
      "     zip       phone        company_name  \n",
      "0  07070  2015558966     The Power Group  \n",
      "1  10154  2125558725           AMF Corp.  \n",
      "2  19301  2155556513  Darling Associates  \n",
      "3  37919  6155555463              P.S.C.  \n",
      "4  46032  3175558437          Amo & Sons  \n",
      "\n",
      "Table: Employee, Rows: 75\n",
      "   emp_id  manager_id emp_fname emp_lname  dept_id                     street  \\\n",
      "0    1013         703    Joseph    Barker      500              58 West Drive   \n",
      "1     102         501      Fran   Whitney      100  49 East Washington Street   \n",
      "2    1021         902      Paul  Sterling      200        112 Endicott Street   \n",
      "3    1039         902  Shih Lin      Chao      200          59 Holyoke Street   \n",
      "4     105         501   Matthew      Cobb      100         77 Pleasant Street   \n",
      "\n",
      "        city state  zip_code       phone status  ss_number   salary  \\\n",
      "0    Bedford    MA      1730  6175558021      A   23470756  27290.0   \n",
      "1    Needham    MA      2192  6175553985      A   17349033  45700.0   \n",
      "2    Concord    MA      1742  5085550295      A   37846595  64900.0   \n",
      "3  Lexington    MA      2173  6175555921      A   46973741  33890.0   \n",
      "4    Waltham    MA      2154  6175553840      A   52345739  62000.0   \n",
      "\n",
      "    start_date   birth_date bene_health_ins bene_life_ins bene_day_care sex  \n",
      "0  10-Sep-2019  14-Feb-1996               N             Y             N   M  \n",
      "1  26-Feb-2013  05-Jun-1985               Y             Y             N   F  \n",
      "2  28-Oct-2019  27-Feb-1977               Y             Y             Y   M  \n",
      "3  11-Nov-2019  12-Dec-1996               N             Y             Y   M  \n",
      "4  02-Jul-2013  04-Dec-1987               Y             Y             N   M  \n",
      "\n",
      "Table: Sales_Order, Rows: 650\n",
      "     id  cust_id   order_date   region  sales_rep\n",
      "0  2001      101  14-Mar-2022  Eastern        299\n",
      "1  2002      102  18-Mar-2022  Eastern        467\n",
      "2  2003      103  21-Mar-2022  Eastern       1039\n",
      "3  2004      104  23-Mar-2022    South        902\n",
      "4  2005      101  24-Mar-2022  Eastern        856\n",
      "\n",
      "Table: Sales_Order_Item, Rows: 1103\n",
      "     id  line_id  prod_id  quantity    ship_date\n",
      "0  2001        1      300        12  15-Sep-2022\n",
      "1  2001        2      301        12  14-Sep-2022\n",
      "2  2001        3      302        12  14-Sep-2022\n",
      "3  2002        1      400        24  18-Sep-2022\n",
      "4  2002        2      401        24  18-Sep-2022\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the SQLite database\n",
    "sqlite_file = \"databases/aenc.sqlite\"\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "\n",
    "# Get a list of all tables in the database\n",
    "query = \"SELECT name FROM sqlite_master WHERE type='table';\"\n",
    "tables = pd.read_sql(query, conn)\n",
    "table_names = tables['name'].tolist()\n",
    "print(f\"Found tables: {table_names}\")\n",
    "\n",
    "# Initialize a dictionary to store DataFrames\n",
    "df_aenc = {}\n",
    "\n",
    "# Loop through each table and load it into a DataFrame\n",
    "for table_name in table_names:\n",
    "    print(f\"Loading table: {table_name}\")\n",
    "    try:\n",
    "        # Read the table into a DataFrame\n",
    "        df = pd.read_sql(f\"SELECT * FROM {table_name};\", conn)\n",
    "        # Store the DataFrame in the dictionary with the table name as the key\n",
    "        df_aenc[table_name] = df\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load table {table_name}: {e}\")\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Access individual DataFrames by their table name\n",
    "for table_name, df in df_aenc.items():\n",
    "    print(f\"Table: {table_name}, Rows: {len(df)}\\n{df.head()}\\n\")\n",
    "\n",
    "\n",
    "# Clean NaN values in the DataFrames\n",
    "df_aenc = clean_nan_values(df_aenc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Inlezen database: NorthWind SQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabel 'Employees' ingelezen met 9 rijen en 18 kolommen.\n",
      "Tabel 'Categories' ingelezen met 8 rijen en 4 kolommen.\n",
      "Tabel 'Customers' ingelezen met 91 rijen en 11 kolommen.\n",
      "Tabel 'Shippers' ingelezen met 3 rijen en 3 kolommen.\n",
      "Tabel 'Suppliers' ingelezen met 29 rijen en 12 kolommen.\n",
      "Tabel 'Orders' ingelezen met 830 rijen en 14 kolommen.\n",
      "Tabel 'Products' ingelezen met 77 rijen en 10 kolommen.\n",
      "Tabel 'OrderDetails' ingelezen met 2155 rijen en 5 kolommen.\n",
      "Tabel 'CustomerCustomerDemo' ingelezen met 0 rijen en 2 kolommen.\n",
      "Tabel 'CustomerDemographics' ingelezen met 0 rijen en 2 kolommen.\n",
      "Tabel 'Region' ingelezen met 4 rijen en 2 kolommen.\n",
      "Tabel 'Territories' ingelezen met 53 rijen en 3 kolommen.\n",
      "Tabel 'EmployeeTerritories' ingelezen met 49 rijen en 2 kolommen.\n",
      "\n",
      "Table: Employees\n",
      "Columns: ['EmployeeID', 'LastName', 'FirstName', 'Title', 'TitleOfCourtesy', 'BirthDate', 'HireDate', 'Address', 'City', 'Region', 'PostalCode', 'Country', 'HomePhone', 'Extension', 'Photo', 'Notes', 'ReportsTo', 'PhotoPath']\n",
      "   EmployeeID   LastName FirstName                  Title TitleOfCourtesy  \\\n",
      "0           1    Davolio     Nancy   Sales Representative             Ms.   \n",
      "1           2     Fuller    Andrew  Vice President, Sales             Dr.   \n",
      "2           3  Leverling     Janet   Sales Representative             Ms.   \n",
      "3           4    Peacock  Margaret   Sales Representative            Mrs.   \n",
      "4           5   Buchanan    Steven          Sales Manager             Mr.   \n",
      "\n",
      "   BirthDate   HireDate                    Address      City Region  \\\n",
      "0 1974-12-08 2018-05-01  507 - 20th Ave. E.Apt. 2A   Seattle     WA   \n",
      "1 1978-02-19 2018-08-14         908 W. Capital Way    Tacoma     WA   \n",
      "2 1989-08-30 2018-04-01         722 Moss Bay Blvd.  Kirkland     WA   \n",
      "3 1963-09-19 2019-05-03       4110 Old Redmond Rd.   Redmond     WA   \n",
      "4 1981-03-04 2019-10-17            14 Garrett Hill    London   None   \n",
      "\n",
      "  PostalCode Country       HomePhone Extension  \\\n",
      "0      98122     USA  (206) 555-9857      5467   \n",
      "1      98401     USA  (206) 555-9482      3457   \n",
      "2      98033     USA  (206) 555-3412      3355   \n",
      "3      98052     USA  (206) 555-8122      5176   \n",
      "4    SW1 8JR      UK   (71) 555-4848      3453   \n",
      "\n",
      "                                               Photo  \\\n",
      "0  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "1  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "2  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "3  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "4  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...   \n",
      "\n",
      "                                               Notes  ReportsTo  \\\n",
      "0  Education includes a BA in psychology from Col...        2.0   \n",
      "1  Andrew received his BTS commercial in 1974 and...        NaN   \n",
      "2  Janet has a BS degree in chemistry from Boston...        2.0   \n",
      "3  Margaret holds a BA in English literature from...        2.0   \n",
      "4  Steven Buchanan graduated from St. Andrews Uni...        2.0   \n",
      "\n",
      "                                PhotoPath  \n",
      "0    http://accweb/emmployees/davolio.bmp  \n",
      "1     http://accweb/emmployees/fuller.bmp  \n",
      "2  http://accweb/emmployees/leverling.bmp  \n",
      "3    http://accweb/emmployees/peacock.bmp  \n",
      "4   http://accweb/emmployees/buchanan.bmp  \n",
      "\n",
      "Table: Categories\n",
      "Columns: ['CategoryID', 'CategoryName', 'Description', 'Picture']\n",
      "   CategoryID    CategoryName  \\\n",
      "0           1       Beverages   \n",
      "1           2      Condiments   \n",
      "2           3     Confections   \n",
      "3           4  Dairy Products   \n",
      "4           5  Grains/Cereals   \n",
      "\n",
      "                                         Description  \\\n",
      "0        Soft drinks, coffees, teas, beers, and ales   \n",
      "1  Sweet and savory sauces, relishes, spreads, an...   \n",
      "2                Desserts, candies, and sweet breads   \n",
      "3                                            Cheeses   \n",
      "4                Breads, crackers, pasta, and cereal   \n",
      "\n",
      "                                             Picture  \n",
      "0  b\"\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...  \n",
      "1  b\"\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...  \n",
      "2  b\"\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...  \n",
      "3  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...  \n",
      "4  b'\\x15\\x1c/\\x00\\x02\\x00\\x00\\x00\\r\\x00\\x0e\\x00\\...  \n",
      "\n",
      "Table: Customers\n",
      "Columns: ['CustomerID', 'CompanyName', 'ContactName', 'ContactTitle', 'Address', 'City', 'Region', 'PostalCode', 'Country', 'Phone', 'Fax']\n",
      "  CustomerID                         CompanyName         ContactName  \\\n",
      "0      ALFKI                 Alfreds Futterkiste        Maria Anders   \n",
      "1      ANATR  Ana Trujillo Emparedados y helados        Ana Trujillo   \n",
      "2      ANTON             Antonio Moreno Taquería      Antonio Moreno   \n",
      "3      AROUT                     Around the Horn        Thomas Hardy   \n",
      "4      BERGS                  Berglunds snabbköp  Christina Berglund   \n",
      "\n",
      "           ContactTitle                        Address         City Region  \\\n",
      "0  Sales Representative                  Obere Str. 57       Berlin   None   \n",
      "1                 Owner  Avda. de la Constitución 2222  México D.F.   None   \n",
      "2                 Owner                Mataderos  2312  México D.F.   None   \n",
      "3  Sales Representative                120 Hanover Sq.       London   None   \n",
      "4   Order Administrator                Berguvsvägen  8        Luleå   None   \n",
      "\n",
      "  PostalCode  Country           Phone             Fax  \n",
      "0      12209  Germany     030-0074321     030-0076545  \n",
      "1      05021   Mexico    (5) 555-4729    (5) 555-3745  \n",
      "2      05023   Mexico    (5) 555-3932            None  \n",
      "3    WA1 1DP       UK  (171) 555-7788  (171) 555-6750  \n",
      "4   S-958 22   Sweden   0921-12 34 65   0921-12 34 67  \n",
      "\n",
      "Table: Shippers\n",
      "Columns: ['ShipperID', 'CompanyName', 'Phone']\n",
      "   ShipperID       CompanyName           Phone\n",
      "0          1    Speedy Express  (503) 555-9831\n",
      "1          2    United Package  (503) 555-3199\n",
      "2          3  Federal Shipping  (503) 555-9931\n",
      "\n",
      "Table: Suppliers\n",
      "Columns: ['SupplierID', 'CompanyName', 'ContactName', 'ContactTitle', 'Address', 'City', 'Region', 'PostalCode', 'Country', 'Phone', 'Fax', 'HomePage']\n",
      "   SupplierID                         CompanyName                 ContactName  \\\n",
      "0           1                      Exotic Liquids            Charlotte Cooper   \n",
      "1           2          New Orleans Cajun Delights               Shelley Burke   \n",
      "2           3           Grandma Kelly's Homestead               Regina Murphy   \n",
      "3           4                       Tokyo Traders                Yoshi Nagase   \n",
      "4           5  Cooperativa de Quesos 'Las Cabras'  Antonio del Valle Saavedra   \n",
      "\n",
      "           ContactTitle                    Address         City    Region  \\\n",
      "0    Purchasing Manager             49 Gilbert St.       London      None   \n",
      "1   Order Administrator             P.O. Box 78934  New Orleans        LA   \n",
      "2  Sales Representative             707 Oxford Rd.    Ann Arbor        MI   \n",
      "3     Marketing Manager  9-8 Sekimai Musashino-shi        Tokyo      None   \n",
      "4  Export Administrator          Calle del Rosal 4       Oviedo  Asturias   \n",
      "\n",
      "  PostalCode Country           Phone             Fax     HomePage  \n",
      "0    EC1 4SD      UK  (171) 555-2222            None         None  \n",
      "1      70117     USA  (100) 555-4822            None  #CAJUN.HTM#  \n",
      "2      48104     USA  (313) 555-5735  (313) 555-3349         None  \n",
      "3        100   Japan  (03) 3555-5011            None         None  \n",
      "4      33007   Spain  (98) 598 76 54            None         None  \n",
      "\n",
      "Table: Orders\n",
      "Columns: ['OrderID', 'CustomerID', 'EmployeeID', 'OrderDate', 'RequiredDate', 'ShippedDate', 'ShipVia', 'Freight', 'ShipName', 'ShipAddress', 'ShipCity', 'ShipRegion', 'ShipPostalCode', 'ShipCountry']\n",
      "   OrderID CustomerID  EmployeeID  OrderDate RequiredDate ShippedDate  \\\n",
      "0    10248      VINET           5 2022-07-04   2022-08-01  2022-07-16   \n",
      "1    10249      TOMSP           6 2022-07-05   2022-08-16  2022-07-10   \n",
      "2    10250      HANAR           4 2022-07-08   2022-08-05  2022-07-12   \n",
      "3    10251      VICTE           3 2022-07-08   2022-08-05  2022-07-15   \n",
      "4    10252      SUPRD           4 2022-07-09   2022-08-06  2022-07-11   \n",
      "\n",
      "   ShipVia  Freight                   ShipName           ShipAddress  \\\n",
      "0        3    32.38  Vins et alcools Chevalier    59 rue de l'Abbaye   \n",
      "1        1    11.61         Toms Spezialitäten         Luisenstr. 48   \n",
      "2        2    65.83              Hanari Carnes       Rua do Paço, 67   \n",
      "3        1    41.34       Victuailles en stock    2, rue du Commerce   \n",
      "4        2    51.30           Suprêmes délices  Boulevard Tirou, 255   \n",
      "\n",
      "         ShipCity ShipRegion ShipPostalCode ShipCountry  \n",
      "0           Reims       None          51100      France  \n",
      "1         Münster       None          44087     Germany  \n",
      "2  Rio de Janeiro         RJ      05454-876      Brazil  \n",
      "3            Lyon       None          69004      France  \n",
      "4       Charleroi       None         B-6000     Belgium  \n",
      "\n",
      "Table: Products\n",
      "Columns: ['ProductID', 'ProductName', 'SupplierID', 'CategoryID', 'QuantityPerUnit', 'UnitPrice', 'UnitsInStock', 'UnitsOnOrder', 'ReorderLevel', 'Discontinued']\n",
      "   ProductID                   ProductName  SupplierID  CategoryID  \\\n",
      "0          1                          Chai           1           1   \n",
      "1          2                         Chang           1           1   \n",
      "2          3                 Aniseed Syrup           1           2   \n",
      "3          4  Chef Anton's Cajun Seasoning           2           2   \n",
      "4          5        Chef Anton's Gumbo Mix           2           2   \n",
      "\n",
      "       QuantityPerUnit  UnitPrice  UnitsInStock  UnitsOnOrder  ReorderLevel  \\\n",
      "0   10 boxes x 20 bags      18.00            39             0            10   \n",
      "1   24 - 12 oz bottles      19.00            17            40            25   \n",
      "2  12 - 550 ml bottles      10.00            13            70            25   \n",
      "3       48 - 6 oz jars      22.00            53             0             0   \n",
      "4             36 boxes      21.35             0             0             0   \n",
      "\n",
      "   Discontinued  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4          True  \n",
      "\n",
      "Table: OrderDetails\n",
      "Columns: ['OrderID', 'ProductID', 'UnitPrice', 'Quantity', 'Discount']\n",
      "   OrderID  ProductID  UnitPrice  Quantity  Discount\n",
      "0    10248         11       14.0        12       0.0\n",
      "1    10248         42        9.8        10       0.0\n",
      "2    10248         72       34.8         5       0.0\n",
      "3    10249         14       18.6         9       0.0\n",
      "4    10249         51       42.4        40       0.0\n",
      "\n",
      "Table: CustomerCustomerDemo\n",
      "Columns: ['CustomerID', 'CustomerTypeID']\n",
      "Empty DataFrame\n",
      "Columns: [CustomerID, CustomerTypeID]\n",
      "Index: []\n",
      "\n",
      "Table: CustomerDemographics\n",
      "Columns: ['CustomerTypeID', 'CustomerDesc']\n",
      "Empty DataFrame\n",
      "Columns: [CustomerTypeID, CustomerDesc]\n",
      "Index: []\n",
      "\n",
      "Table: Region\n",
      "Columns: ['RegionID', 'RegionDescription']\n",
      "   RegionID                                  RegionDescription\n",
      "0         1  Eastern                                       ...\n",
      "1         2  Western                                       ...\n",
      "2         3  Northern                                      ...\n",
      "3         4  Southern                                      ...\n",
      "\n",
      "Table: Territories\n",
      "Columns: ['TerritoryID', 'TerritoryDescription', 'RegionID']\n",
      "  TerritoryID                               TerritoryDescription  RegionID\n",
      "0       01581  Westboro                                      ...         1\n",
      "1       01730  Bedford                                       ...         1\n",
      "2       01833  Georgetow                                     ...         1\n",
      "3       02116  Boston                                        ...         1\n",
      "4       02139  Cambridge                                     ...         1\n",
      "\n",
      "Table: EmployeeTerritories\n",
      "Columns: ['EmployeeID', 'TerritoryID']\n",
      "   EmployeeID TerritoryID\n",
      "0           1       06897\n",
      "1           1       19713\n",
      "2           2       01581\n",
      "3           2       01730\n",
      "4           2       01833\n"
     ]
    }
   ],
   "source": [
    "# Verbindingsgegevens\n",
    "server = '127.0.0.1'        \n",
    "port = '1433'               \n",
    "database = 'NorthWind'         \n",
    "username = 'SA'             \n",
    "password = 'iDTyjZx7dRL4'  \n",
    "\n",
    "# Connection string\n",
    "connection_string = (\n",
    "    f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"SERVER={server},{port};\"\n",
    "    f\"DATABASE={database};\"\n",
    "    f\"UID={username};\"\n",
    "    f\"PWD={password};\"\n",
    "    \"TrustServerCertificate=yes;\"\n",
    "    \"Timeout=30;\"\n",
    ")\n",
    "\n",
    "# Maak verbinding met de database\n",
    "conn = pyodbc.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Haal alle tabellen op\n",
    "cursor.execute(\"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE'\")\n",
    "tables = [row.TABLE_NAME for row in cursor.fetchall()]\n",
    "\n",
    "# Dictionary om alle dataframes op te slaan\n",
    "df_NorthWind = {}\n",
    "\n",
    "# Loop door alle tabellen en laad ze in Pandas DataFrames\n",
    "for table in tables:\n",
    "    query = f\"SELECT * FROM [{table}]\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    df_NorthWind[table] = df\n",
    "    print(f\"Tabel '{table}' ingelezen met {df.shape[0]} rijen en {df.shape[1]} kolommen.\")\n",
    "\n",
    "# Sluit de verbinding\n",
    "conn.close()\n",
    "\n",
    "# Print de kolomnamen en de eerste paar rijen van elke DataFrame\n",
    "for table_name, df in df_NorthWind.items():\n",
    "    print(f\"\\nTable: {table_name}\")\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    print(df.head())\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>maak dictionary aan voor alle goede dataframes + mapping dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_sourcedatamodel = {}\n",
    "df_mapping = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Production_ProductCategory\n",
    "<h4> bronnen: Production_ProductCategory + Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MergedCategoryID ProductCategoryID            Name  \\\n",
      "0                  1                 1           Bikes   \n",
      "1                  2                 2      Components   \n",
      "2                  3                 3        Clothing   \n",
      "3                  4                 4     Accessories   \n",
      "4                  5                 1       Beverages   \n",
      "5                  6                 2      Condiments   \n",
      "6                  7                 3     Confections   \n",
      "7                  8                 4  Dairy Products   \n",
      "8                  9                 5  Grains/Cereals   \n",
      "9                 10                 6    Meat/Poultry   \n",
      "10                11                 7         Produce   \n",
      "11                12                 8         Seafood   \n",
      "\n",
      "                                  rowguid       ModifiedDate          Source  \\\n",
      "0   {CFBDA25C-DF71-47A7-B81B64EE161AA37C}  04/30/18 00:00:00  AdventureWorks   \n",
      "1   {C657828D-D808-4ABA-91A3AF2CE02300E9}  04/30/18 00:00:00  AdventureWorks   \n",
      "2   {10A7C342-CA82-48D4-8A3846A2EB089B74}  04/30/18 00:00:00  AdventureWorks   \n",
      "3   {2BE3BE36-D9A2-4EEE-B593ED895D97C2A6}  04/30/18 00:00:00  AdventureWorks   \n",
      "4                                                                  NorthWind   \n",
      "5                                                                  NorthWind   \n",
      "6                                                                  NorthWind   \n",
      "7                                                                  NorthWind   \n",
      "8                                                                  NorthWind   \n",
      "9                                                                  NorthWind   \n",
      "10                                                                 NorthWind   \n",
      "11                                                                 NorthWind   \n",
      "\n",
      "                                          Description  \n",
      "0                                                      \n",
      "1                                                      \n",
      "2                                                      \n",
      "3                                                      \n",
      "4         Soft drinks, coffees, teas, beers, and ales  \n",
      "5   Sweet and savory sauces, relishes, spreads, an...  \n",
      "6                 Desserts, candies, and sweet breads  \n",
      "7                                             Cheeses  \n",
      "8                 Breads, crackers, pasta, and cereal  \n",
      "9                                      Prepared meats  \n",
      "10                          Dried fruit and bean curd  \n",
      "11                                   Seaweed and fish  \n"
     ]
    }
   ],
   "source": [
    "# Data opnieuw laden om dubbele kolommen te voorkomen\n",
    "df_product_category = df_AdventureWorks.get(\"Production_ProductCategory\").copy()\n",
    "df_categories = df_NorthWind.get(\"Categories\").copy()\n",
    "\n",
    "# Voeg 'Source' kolom toe\n",
    "df_product_category['Source'] = 'AdventureWorks'\n",
    "df_categories['Source'] = 'NorthWind'\n",
    "\n",
    "\n",
    "# Voeg een unieke sleutel toe (MergedCategoryID) als deze nog niet bestaat\n",
    "if \"MergedCategoryID\" not in df_product_category.columns:\n",
    "    df_product_category.insert(0, \"MergedCategoryID\", range(1, len(df_product_category) + 1))\n",
    "\n",
    "if \"MergedCategoryID\" not in df_categories.columns:\n",
    "    df_categories.insert(0, \"MergedCategoryID\", range(len(df_product_category) + 1, len(df_product_category) + len(df_categories) + 1))\n",
    "\n",
    "# Hernoem kolommen zodat ze overeenkomen\n",
    "df_categories.rename(columns={\n",
    "    \"CategoryID\": \"ProductCategoryID\", \n",
    "    \"CategoryName\": \"Name\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Combineer de twee tabellen onder elkaar\n",
    "merged_df_productCategorie = pd.concat([df_product_category, df_categories], ignore_index=True)\n",
    "\n",
    "# Vul NaN-waarden in met lege strings (optioneel)\n",
    "merged_df_productCategorie.fillna(\"\", inplace=True)\n",
    "\n",
    "# Verwijder de kolom ShipDate als deze bestaat\n",
    "if \"Picture\" in merged_df_productCategorie.columns:\n",
    "    merged_df_productCategorie = merged_df_productCategorie.drop(columns=[\"Picture\"])\n",
    "\n",
    "\n",
    "\n",
    "#mapping van de categorieen per bron\n",
    "category_mapping = merged_df_productCategorie[['ProductCategoryID', 'Source', 'MergedCategoryID']]\n",
    "\n",
    "dfs_sourcedatamodel[\"Production_ProductCategory\"] = merged_df_productCategorie\n",
    "df_mapping[\"category_mapping\"] = category_mapping\n",
    "\n",
    "\n",
    "\n",
    "# Print het resultaat\n",
    "print(merged_df_productCategorie)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Production_Product\n",
    "<h4> bronnen: Production_Product + Products + Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MergedID ProductID                   Name ProductNumber MakeFlag  \\\n",
      "0           1         1        Adjustable Race       AR-5381        0   \n",
      "1           2         2           Bearing Ball       BA-8327        0   \n",
      "2           3         3        BB Ball Bearing       BE-2349       -1   \n",
      "3           4         4  Headset Ball Bearings       BE-2908        0   \n",
      "4           5       316                  Blade       BL-2036       -1   \n",
      "..        ...       ...                    ...           ...      ...   \n",
      "586       587       500                  Visor          None     None   \n",
      "587       588       501                  Visor          None     None   \n",
      "588       589       600             Sweatshirt          None     None   \n",
      "589       590       601             Sweatshirt          None     None   \n",
      "590       591       700                 Shorts          None     None   \n",
      "\n",
      "    FinishedGoodsFlag  Color SafetyStockLevel ReorderPoint StandardCost  ...  \\\n",
      "0                   0   None             1000          750          0.0  ...   \n",
      "1                   0   None             1000          750          0.0  ...   \n",
      "2                   0   None              800          600          0.0  ...   \n",
      "3                   0   None              800          600          0.0  ...   \n",
      "4                   0   None              800          600          0.0  ...   \n",
      "..                ...    ...              ...          ...          ...  ...   \n",
      "586              None  White             None         None         None  ...   \n",
      "587              None  Black             None         None         None  ...   \n",
      "588              None  Green             None         None         None  ...   \n",
      "589              None   Blue             None         None         None  ...   \n",
      "590              None  Black             None         None         None  ...   \n",
      "\n",
      "           ModifiedDate ProductCategoryID          Source QuantityPerUnit  \\\n",
      "0   2024-02-08 10:01:37               NaN  AdventureWorks            None   \n",
      "1   2024-02-08 10:01:37               NaN  AdventureWorks            None   \n",
      "2   2024-02-08 10:01:37               NaN  AdventureWorks            None   \n",
      "3   2024-02-08 10:01:37               NaN  AdventureWorks            None   \n",
      "4   2024-02-08 10:01:37               NaN  AdventureWorks            None   \n",
      "..                  ...               ...             ...             ...   \n",
      "586                 NaT               NaN            AENC            None   \n",
      "587                 NaT               NaN            AENC            None   \n",
      "588                 NaT               NaN            AENC            None   \n",
      "589                 NaT               NaN            AENC            None   \n",
      "590                 NaT               NaN            AENC            None   \n",
      "\n",
      "           description Discontinued SupplierID quantity UnitsInStock  \\\n",
      "0                 None         None       None     None         None   \n",
      "1                 None         None       None     None         None   \n",
      "2                 None         None       None     None         None   \n",
      "3                 None         None       None     None         None   \n",
      "4                 None         None       None     None         None   \n",
      "..                 ...          ...        ...      ...          ...   \n",
      "586        Cloth Visor         None       None       36         None   \n",
      "587      Plastic Visor         None       None       28         None   \n",
      "588  Hooded Sweatshirt         None       None       39         None   \n",
      "589  Zipped Sweatshirt         None       None       32         None   \n",
      "590      Cotton Shorts         None       None       80         None   \n",
      "\n",
      "    UnitsOnOrder  \n",
      "0           None  \n",
      "1           None  \n",
      "2           None  \n",
      "3           None  \n",
      "4           None  \n",
      "..           ...  \n",
      "586         None  \n",
      "587         None  \n",
      "588         None  \n",
      "589         None  \n",
      "590         None  \n",
      "\n",
      "[591 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Functie om alle datums correct te converteren\n",
    "def convert_dates(df):\n",
    "    date_columns = [col for col in df.columns if \"date\" in col.lower()]\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')  # Zet om naar datetime\n",
    "    return df\n",
    "\n",
    "# Functie om -1 te vervangen door None\n",
    "def clean_negative_values(df):\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        df[col] = df[col].apply(lambda x: None if x == -1 else x)\n",
    "    return df\n",
    "\n",
    "# Data opnieuw laden om dubbele kolommen te voorkomen\n",
    "df_production_product = df_AdventureWorks.get(\"Production_Product\").copy()\n",
    "df_products = df_NorthWind.get(\"Products\").copy()\n",
    "df_product = df_aenc.get(\"Product\").copy()\n",
    "\n",
    "# Voeg 'Source' kolom toe\n",
    "df_production_product['Source'] = 'AdventureWorks'\n",
    "df_products['Source'] = 'NorthWind'\n",
    "df_product['Source'] = 'AENC'\n",
    "\n",
    "# Maak een unieke MergedID voor elke rij\n",
    "df_production_product.insert(0, \"MergedID\", range(1, len(df_production_product) + 1))\n",
    "df_products.insert(0, \"MergedID\", range(len(df_production_product) + 1, len(df_production_product) + len(df_products) + 1))\n",
    "df_product.insert(0, \"MergedID\", range(len(df_production_product) + len(df_products) + 1, \n",
    "                                       len(df_production_product) + len(df_products) + len(df_product) + 1))\n",
    "\n",
    "# Zorg dat alle tabellen dezelfde kolommen hebben\n",
    "df_products.rename(columns={\"ProductName\": \"Name\", \"CategoryID\": \"ProductCategoryID\", \"UnitPrice\": \"ListPrice\"}, inplace=True)\n",
    "df_product.rename(columns={\"id\": \"ProductID\", \"name\": \"Name\", \"prod_size\": \"Size\", \"unit_price\": \"ListPrice\", \"Category\": \"ProductCategoryID\"}, inplace=True)\n",
    "\n",
    "# Voeg ontbrekende kolommen toe met lege waarden\n",
    "all_columns = set(df_production_product.columns).union(set(df_products.columns)).union(set(df_product.columns))\n",
    "for df in [df_production_product, df_products, df_product]:\n",
    "    for col in all_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "# Zet alle tabellen onder elkaar\n",
    "merged_df_product = pd.concat([df_production_product, df_products, df_product], ignore_index=True)\n",
    "\n",
    "# Datumconversie toepassen\n",
    "merged_df_product = convert_dates(merged_df_product)\n",
    "\n",
    "# Negatieve waarden verwijderen\n",
    "merged_df_product = clean_negative_values(merged_df_product)\n",
    "\n",
    "# Verwijder 'picture_name' en 'DiscontinuedDate' kolommen\n",
    "merged_df_product.drop(columns=[\"picture_name\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Hernoem 'ReorderLevel' naar 'ReorderPoint' en zet ze samen in één kolom\n",
    "if \"ReorderLevel\" in merged_df_product.columns and \"ReorderPoint\" in merged_df_product.columns:\n",
    "    merged_df_product[\"ReorderPoint\"] = merged_df_product[\"ReorderPoint\"].combine_first(merged_df_product[\"ReorderLevel\"])\n",
    "    merged_df_product.drop(columns=[\"ReorderLevel\"], inplace=True)\n",
    "\n",
    "# Hernoem 'color' zodat beide versies samengevoegd worden in één kolom\n",
    "if \"color\" in merged_df_product.columns and \"Color\" in merged_df_product.columns:\n",
    "    merged_df_product[\"Color\"] = merged_df_product[\"Color\"].combine_first(merged_df_product[\"color\"])\n",
    "    merged_df_product.drop(columns=[\"color\"], inplace=True)\n",
    "\n",
    "product_mapping = merged_df_product[['ProductID', 'Source', 'MergedID']]\n",
    "\n",
    "# Merge op ProductCategoryID + Source om conflicten te vermijden\n",
    "merged_df_product = merged_df_product.merge(\n",
    "    category_mapping,\n",
    "    how='left',\n",
    "    left_on=['ProductCategoryID', 'Source'],\n",
    "    right_on=['ProductCategoryID', 'Source']\n",
    ")\n",
    "\n",
    "# Vervang de oude ProductCategoryID door de nieuwe MergedCategoryID\n",
    "merged_df_product['ProductCategoryID'] = merged_df_product['MergedCategoryID']\n",
    "merged_df_product.drop(columns=['MergedCategoryID'], inplace=True, errors='ignore')\n",
    "\n",
    "# Verwijder de kolom ShipDate als deze bestaat\n",
    "if \"DiscontinuedDate\" in merged_df_product.columns:\n",
    "    merged_df_product = merged_df_product.drop(columns=[\"DiscontinuedDate\"])\n",
    "\n",
    "# Data opslaan in het data warehouse dictionary\n",
    "dfs_sourcedatamodel[\"Production_Product\"] = merged_df_product\n",
    "df_mapping[\"product_mapping\"] = product_mapping\n",
    "\n",
    "# Print het resultaat\n",
    "print(merged_df_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Purchasing_Vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 104\n",
      "  BusinessEntityID AccountNumber                     Name CreditRating  \\\n",
      "0             1492  AUSTRALI0001  Australia Bike Retailer            1   \n",
      "1             1494  ALLENSON0001          Allenson Cycles            2   \n",
      "2             1496  ADVANCED0001        Advanced Bicycles            1   \n",
      "3             1498    TRIKES0001             Trikes, Inc.            2   \n",
      "4             1500   MORGANB0001  Morgan Bike Accessories            1   \n",
      "\n",
      "  PreferredVendorStatus ActiveFlag PurchasingWebServiceURL       ModifiedDate  \n",
      "0                    -1         -1                    None  12/23/21 00:00:00  \n",
      "1                    -1         -1                    None  04/25/21 00:00:00  \n",
      "2                    -1         -1                    None  04/25/21 00:00:00  \n",
      "3                    -1         -1                    None  02/03/22 00:00:00  \n",
      "4                    -1         -1                    None  02/02/22 00:00:00  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get dataframe from dictionary\n",
    "purchasing_vendor_df = df_AdventureWorks.get(\"Purchasing_Vendor\")\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if purchasing_vendor_df is not None:\n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"Purchasing_Vendor\"] = purchasing_vendor_df\n",
    "\n",
    "    print(f\"Rows: {len(purchasing_vendor_df)}\")\n",
    "    print(purchasing_vendor_df.head())\n",
    "else:\n",
    "    print(\"The table 'Purchasing_Vendor' does not exist in database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: sales_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 701\n",
      "  BusinessEntityID                            Name SalesPersonID  \\\n",
      "0              292            Next-Door Bike Store           279   \n",
      "1              294  Professional Sales and Service           276   \n",
      "2              296                  Riders Company           277   \n",
      "3              298              The Bike Mechanics           275   \n",
      "4              300               Nationwide Supply           286   \n",
      "\n",
      "                                 rowguid       ModifiedDate  \n",
      "0  {A22517E3-848D-4EBE-B9D97437F3432304}  09/12/14 11:15:07  \n",
      "1  {B50CA50B-C601-4A13-B07E2C63862D71B4}  09/12/14 11:15:07  \n",
      "2  {337C3688-1339-4E1A-A08AB54B23566E49}  09/12/14 11:15:07  \n",
      "3  {7894F278-F0C8-4D16-BD75213FDBF13023}  09/12/14 11:15:07  \n",
      "4  {C3FC9705-A8C4-4F3A-9550EB2FA4B7B64D}  09/12/14 11:15:07  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get dataframe from dictionary\n",
    "sales_store_df = df_AdventureWorks.get(\"Sales_Store\")\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if sales_store_df is not None:\n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"Sales_Store\"] = sales_store_df\n",
    "\n",
    "    print(f\"Rows: {len(sales_store_df)}\")\n",
    "    print(sales_store_df.head())\n",
    "else:\n",
    "    print(\"The table does not exist in database.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> tabel: employee_territories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rows: 49\n",
      "   EmployeeID TerritoryID\n",
      "0      100001       06897\n",
      "1      100001       19713\n",
      "2      100002       01581\n",
      "3      100002       01730\n",
      "4      100002       01833\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get dataframe from dictionary\n",
    "employeeTerritories_df = df_NorthWind.get(\"EmployeeTerritories\")\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if employeeTerritories_df is not None:\n",
    "     # Apply the same offset as Employee_df2 for AENC employees\n",
    "    employeeTerritories_df[\"EmployeeID\"] = employeeTerritories_df[\"EmployeeID\"].astype(int) + 100000  \n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"EmployeeTerritories\"] = employeeTerritories_df\n",
    "\n",
    "    print(f\" Rows: {len(employeeTerritories_df)}\")\n",
    "    print(employeeTerritories_df.head())\n",
    "else:\n",
    "    print(\"The table does not exist in database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Territories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rows: 53\n",
      "  TerritoryID                               TerritoryDescription  RegionID\n",
      "0       01581  Westboro                                      ...         1\n",
      "1       01730  Bedford                                       ...         1\n",
      "2       01833  Georgetow                                     ...         1\n",
      "3       02116  Boston                                        ...         1\n",
      "4       02139  Cambridge                                     ...         1\n"
     ]
    }
   ],
   "source": [
    "#get dataframe from dictionary\n",
    "territories_df = df_NorthWind.get(\"Territories\")\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if territories_df is not None:\n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"Territories\"] = territories_df\n",
    "\n",
    "    print(f\" Rows: {len(territories_df)}\")\n",
    "    print(territories_df.head())\n",
    "else:\n",
    "    print(\"The table does not exist in database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rows: 4\n",
      "   RegionID                                  RegionDescription\n",
      "0         1  Eastern                                       ...\n",
      "1         2  Western                                       ...\n",
      "2         3  Northern                                      ...\n",
      "3         4  Southern                                      ...\n"
     ]
    }
   ],
   "source": [
    "#get dataframe from dictionary\n",
    "region_df = df_NorthWind.get(\"Region\")\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if region_df is not None:\n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"Region\"] = region_df\n",
    "\n",
    "    print(f\" Rows: {len(region_df)}\")\n",
    "    print(region_df.head())\n",
    "else:\n",
    "    print(\"The table does not exist in database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Table: Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 33\n",
      "   emp_id bonus_date bonus_amount\n",
      "0  200129  31-dec-24           50\n",
      "1  200195  31-dec-23           50\n",
      "2  200299  31-dec-23          200\n",
      "3  201142  31-dec-23          100\n",
      "4  200129  31-dec-22           50\n"
     ]
    }
   ],
   "source": [
    "# Get dataframe from dictionary\n",
    "bonus_df = df_aenc.get(\"Bonus\")\n",
    "bonus_df = bonus_df.drop_duplicates(subset=[\"emp_id\", \"bonus_date\"])\n",
    "\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if bonus_df is not None:\n",
    "    # Apply the same offset as Employee_df2 for AENC employees\n",
    "    bonus_df[\"emp_id\"] = bonus_df[\"emp_id\"].astype(int) + 200000  \n",
    "\n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"Bonus\"] = bonus_df\n",
    "\n",
    "    print(f\"Rows: {len(bonus_df)}\")\n",
    "    print(bonus_df.head())\n",
    "else:\n",
    "    print(\"The table does not exist in database.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Sales_Customer\n",
    "\n",
    "<h4> Bronnen: Customer + Customers + Sales_Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MergedCustomerID CustomerID PersonID StoreID TerritoryID AccountNumber  \\\n",
      "0                     1          1     None   934.0           1    AW00000001   \n",
      "1                     2          2     None  1028.0           1    AW00000002   \n",
      "2                     3          3     None   642.0           4    AW00000003   \n",
      "3                     4          4     None   932.0           4    AW00000004   \n",
      "4                     5          5     None  1026.0           4    AW00000005   \n",
      "...                 ...        ...      ...     ...         ...           ...   \n",
      "20032             20033      WARTH     None    None        None          None   \n",
      "20033             20034      WELLI     None    None        None          None   \n",
      "20034             20035      WHITC     None    None        None          None   \n",
      "20035             20036      WILMK     None    None        None          None   \n",
      "20036             20037      WOLZA     None    None        None          None   \n",
      "\n",
      "                                     rowguid       ModifiedDate  \\\n",
      "0      {3F5AE95E-B87D-4AED-95B4C3797AFCB74F}  09/12/24 11:15:07   \n",
      "1      {E552F657-A9AF-4A7D-A645C429D6E02491}  09/12/24 11:15:07   \n",
      "2      {130774B1-DB21-4EF3-98C8C104BCD6ED6D}  09/12/24 11:15:07   \n",
      "3      {FF862851-1DAA-4044-BE7C3E85583C054D}  09/12/24 11:15:07   \n",
      "4      {83905BDC-6F5E-4F71-B162C98DA069F38A}  09/12/24 11:15:07   \n",
      "...                                      ...                ...   \n",
      "20032                                   None               None   \n",
      "20033                                   None               None   \n",
      "20034                                   None               None   \n",
      "20035                                   None               None   \n",
      "20036                                   None               None   \n",
      "\n",
      "               Source             CompanyName  \n",
      "0      AdventureWorks                    None  \n",
      "1      AdventureWorks                    None  \n",
      "2      AdventureWorks                    None  \n",
      "3      AdventureWorks                    None  \n",
      "4      AdventureWorks                    None  \n",
      "...               ...                     ...  \n",
      "20032       NorthWind          Wartian Herkku  \n",
      "20033       NorthWind  Wellington Importadora  \n",
      "20034       NorthWind    White Clover Markets  \n",
      "20035       NorthWind             Wilman Kala  \n",
      "20036       NorthWind          Wolski  Zajazd  \n",
      "\n",
      "[20037 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#get dataframe from dictionary\n",
    "Sales_Customer_df = df_AdventureWorks.get(\"Sales_Customer\")\n",
    "\n",
    "\n",
    "# Laden van de datasets (vervang dit met je eigen DataFrame-imports)\n",
    "Sales_Customer_df = df_AdventureWorks.get(\"Sales_Customer\")\n",
    "customer_df = df_aenc.get(\"Customer\")   \n",
    "customers_df = df_NorthWind.get(\"Customers\")\n",
    "# Voeg 'Source' kolom toe\n",
    "Sales_Customer_df[\"Source\"] = \"AdventureWorks\"\n",
    "customer_df[\"Source\"] = \"AENC\"\n",
    "customers_df[\"Source\"] = \"NorthWind\"\n",
    "\n",
    "# Zorg dat CustomerID overal een string is om inconsistenties te voorkomen\n",
    "Sales_Customer_df[\"CustomerID\"] = Sales_Customer_df[\"CustomerID\"].astype(str)\n",
    "customers_df[\"CustomerID\"] = customers_df[\"CustomerID\"].astype(str)\n",
    "customer_df.rename(columns={\"id\": \"CustomerID\"}, inplace=True)\n",
    "customer_df[\"CustomerID\"] = customer_df[\"CustomerID\"].astype(str)\n",
    "\n",
    "# Hernoem kolommen om aan te sluiten bij Sales_Customer structuur\n",
    "customers_df.rename(columns={\"CompanyName\": \"CompanyName\"}, inplace=True)\n",
    "customer_df.rename(columns={\"company_name\": \"CompanyName\"}, inplace=True)\n",
    "\n",
    "# Houd alleen de relevante kolommen\n",
    "Sales_Customer_df = Sales_Customer_df[[\"CustomerID\", \"PersonID\", \"StoreID\", \"TerritoryID\", \"AccountNumber\", \"rowguid\", \"ModifiedDate\", \"Source\"]]\n",
    "customer_df = customer_df[[\"CustomerID\", \"CompanyName\", \"Source\"]]\n",
    "customers_df = customers_df[[\"CustomerID\", \"CompanyName\", \"Source\"]]\n",
    "\n",
    "# Voeg een unieke sleutel toe (MergedCustomerID)\n",
    "Sales_Customer_df.insert(0, \"MergedCustomerID\", range(1, len(Sales_Customer_df) + 1))\n",
    "customer_df.insert(0, \"MergedCustomerID\", range(len(Sales_Customer_df) + 1, len(Sales_Customer_df) + len(customer_df) + 1))\n",
    "customers_df.insert(0, \"MergedCustomerID\", range(len(Sales_Customer_df) + len(customer_df) + 1, len(Sales_Customer_df) + len(customer_df) + len(customers_df) + 1))\n",
    "\n",
    "# Combineer de tabellen onder elkaar\n",
    "merged_customers = pd.concat([Sales_Customer_df, customer_df, customers_df], ignore_index=True)\n",
    "\n",
    "# Vul NaN-waarden in met None (SQL-compatible)\n",
    "merged_customers = merged_customers.where(pd.notna(merged_customers), None)\n",
    "\n",
    "# Mapping maken voor toekomstige foreign key updates\n",
    "customer_mapping = merged_customers[[\"CustomerID\", \"Source\", \"MergedCustomerID\"]]\n",
    "\n",
    "\n",
    "\n",
    "dfs_sourcedatamodel[\"Sales_Customer\"] = merged_customers\n",
    "df_mapping[\"customer_mapping\"] = customer_mapping\n",
    "\n",
    "\n",
    "\n",
    "# Print het resultaat\n",
    "print(merged_customers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Sales_SalesTerritory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rows: 10\n",
      "  TerritoryID       Name CountryRegionCode         Group1       SalesYTD  \\\n",
      "0           1  Northwest                US  North America   7887186.7882   \n",
      "1           2  Northeast                US  North America   2402176.8476   \n",
      "2           3    Central                US  North America    3072175.118   \n",
      "3           4  Southwest                US  North America  10510853.8739   \n",
      "4           5  Southeast                US  North America   2538667.2515   \n",
      "\n",
      "  SalesLastYear CostYTD CostLastYear                                rowguid  \\\n",
      "0  3298694.4938     0.0          0.0  {43689A10-E30B-497F-B0DE11DE20267FF7}   \n",
      "1  3607148.9371     0.0          0.0  {00FB7309-96CC-49E2-83630A1BA72486F2}   \n",
      "2  3205014.0767     0.0          0.0  {DF6E7FD8-1A8D-468C-B103ED8ADDB452C1}   \n",
      "3  5366575.7098     0.0          0.0  {DC3E9EA0-7950-4431-942899DBCBC33865}   \n",
      "4  3925071.4318     0.0          0.0  {6DC4165A-5E4C-42D2-809D4344E0AC75E7}   \n",
      "\n",
      "        ModifiedDate  \n",
      "0  04/30/08 00:00:00  \n",
      "1  04/30/08 00:00:00  \n",
      "2  04/30/08 00:00:00  \n",
      "3  04/30/08 00:00:00  \n",
      "4  04/30/08 00:00:00  \n"
     ]
    }
   ],
   "source": [
    "#get dataframe from dictionary\n",
    "Sales_SalesTerritory_df = df_AdventureWorks.get(\"Sales_SalesTerritory\")\n",
    "Sales_SalesTerritory_df.rename(columns={\"Group\": \"Group1\"}, inplace=True)\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if Sales_SalesTerritory_df is not None:\n",
    "\n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"Sales_SalesTerritory\"] = Sales_SalesTerritory_df\n",
    "\n",
    "    print(f\" Rows: {len(Sales_SalesTerritory_df)}\")\n",
    "    print(Sales_SalesTerritory_df.head())\n",
    "else:\n",
    "    print(\"The table does not exist in database.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Purchasing_PurchaseOrderHeader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rows: 4012\n",
      "  PurchaseOrderID RevisionNumber Status EmployeeID VendorID ShipMethodID  \\\n",
      "0               1              4      4        258     1580            3   \n",
      "1               2              4      1        254     1496            5   \n",
      "2               3              4      4        257     1494            2   \n",
      "3               4              4      3        261     1650            5   \n",
      "4               5              4      4        251     1654            4   \n",
      "\n",
      "           OrderDate           ShipDate  SubTotal    TaxAmt   Freight  \\\n",
      "0  04/16/21 00:00:00  04/25/21 00:00:00    201.04   16.0832     5.026   \n",
      "1  04/16/21 00:00:00  04/25/21 00:00:00  272.1015   21.7681    6.8025   \n",
      "2  04/16/21 00:00:00  04/25/21 00:00:00    8847.3   707.784  221.1825   \n",
      "3  04/16/21 00:00:00  04/25/21 00:00:00  171.0765   13.6861    4.2769   \n",
      "4  04/30/21 00:00:00  05/09/21 00:00:00   20397.3  1631.784  509.9325   \n",
      "\n",
      "     TotalDue       ModifiedDate  \n",
      "0    222.1492  04/25/21 00:00:00  \n",
      "1    300.6721  04/25/21 00:00:00  \n",
      "2   9776.2665  04/25/21 00:00:00  \n",
      "3    189.0395  04/25/21 00:00:00  \n",
      "4  22539.0165  05/09/21 00:00:00  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get dataframe from dictionary\n",
    "Purchasing_PurchaseOrderHeader = df_AdventureWorks.get(\"Purchasing_PurchaseOrderHeader\")\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if Purchasing_PurchaseOrderHeader is not None:\n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"Purchasing_PurchaseOrderHeader\"] = Purchasing_PurchaseOrderHeader\n",
    "\n",
    "    print(f\" Rows: {len(Purchasing_PurchaseOrderHeader)}\")\n",
    "    print(Purchasing_PurchaseOrderHeader.head())\n",
    "else:\n",
    "    print(\"The table does not exist in database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Purchasing_PurchaseOrderDetail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with Source == 'NorthWind' have been removed.\n",
      "Rows: 8845\n",
      "  PurchaseOrderID PurchaseOrderDetailID            DueDate OrderQty  \\\n",
      "0               1                     1  04/30/21 00:00:00        4   \n",
      "1               2                     2  04/30/21 00:00:00        3   \n",
      "2               2                     3  04/30/21 00:00:00        3   \n",
      "3               3                     4  04/30/21 00:00:00      550   \n",
      "4               4                     5  04/30/21 00:00:00        3   \n",
      "\n",
      "   ProductID UnitPrice LineTotal ReceivedQty RejectedQty StockedQty  \\\n",
      "0          1     50.26    201.04         3.0         0.0        3.0   \n",
      "1         38     45.12    135.36         3.0         0.0        3.0   \n",
      "2         39   45.5805  136.7415         3.0         0.0        3.0   \n",
      "3        203    16.086    8847.3       550.0         0.0      550.0   \n",
      "4          4   57.0255  171.0765         2.0         1.0        1.0   \n",
      "\n",
      "        ModifiedDate          Source  \n",
      "0  04/23/21 00:00:00  AdventureWorks  \n",
      "1  04/23/21 00:00:00  AdventureWorks  \n",
      "2  04/23/21 00:00:00  AdventureWorks  \n",
      "3  04/23/21 00:00:00  AdventureWorks  \n",
      "4  04/23/21 00:00:00  AdventureWorks  \n",
      "The updated table has been saved to 'Purchasing_PurchaseOrderDetail.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Get the Purchasing_PurchaseOrderDetail DataFrame from the dictionary\n",
    "Purchasing_PurchaseOrderDetail = df_AdventureWorks.get(\"Purchasing_PurchaseOrderDetail\")\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if Purchasing_PurchaseOrderDetail is not None:\n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"Purchasing_PurchaseOrderDetail\"] = Purchasing_PurchaseOrderDetail\n",
    "\n",
    "    # Perform the merge to replace ProductID with MergedID\n",
    "    Purchasing_PurchaseOrderDetail = Purchasing_PurchaseOrderDetail.merge(\n",
    "        product_mapping,  # This contains ProductID, Source, and MergedID\n",
    "        how='left',\n",
    "        left_on=['ProductID'],  # Assuming ProductID exists in this table\n",
    "        right_on=['ProductID']\n",
    "    )\n",
    "\n",
    "    # Replace ProductID with MergedID\n",
    "    Purchasing_PurchaseOrderDetail['ProductID'] = Purchasing_PurchaseOrderDetail['MergedID']\n",
    "\n",
    "    # Drop the MergedID column as it's no longer needed\n",
    "    Purchasing_PurchaseOrderDetail.drop(columns=['MergedID'], inplace=True, errors='ignore')\n",
    "\n",
    "    # Drop rows where Source is 'NorthWind'\n",
    "    if 'Source' in Purchasing_PurchaseOrderDetail.columns:\n",
    "        Purchasing_PurchaseOrderDetail = Purchasing_PurchaseOrderDetail[Purchasing_PurchaseOrderDetail['Source'] != 'NorthWind']\n",
    "        Purchasing_PurchaseOrderDetail.reset_index(drop=True, inplace=True)\n",
    "        print(\"Rows with Source == 'NorthWind' have been removed.\")\n",
    "    else:\n",
    "        print(\"The 'Source' column does not exist in Purchasing_PurchaseOrderDetail.\")\n",
    "\n",
    "    # Update the dictionary with the modified DataFrame\n",
    "    dfs_sourcedatamodel[\"Purchasing_PurchaseOrderDetail\"] = Purchasing_PurchaseOrderDetail\n",
    "\n",
    "    # Print the result\n",
    "    print(f\"Rows: {len(Purchasing_PurchaseOrderDetail)}\")\n",
    "    print(Purchasing_PurchaseOrderDetail.head())\n",
    "\n",
    "   \n",
    "    print(\"The updated table has been saved to 'Purchasing_PurchaseOrderDetail.csv'.\")\n",
    "else:\n",
    "    print(\"The table 'Purchasing_PurchaseOrderDetail' does not exist in the database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Suppliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rows: 29\n",
      "   SupplierID                         CompanyName                 ContactName  \\\n",
      "0           1                      Exotic Liquids            Charlotte Cooper   \n",
      "1           2          New Orleans Cajun Delights               Shelley Burke   \n",
      "2           3           Grandma Kelly's Homestead               Regina Murphy   \n",
      "3           4                       Tokyo Traders                Yoshi Nagase   \n",
      "4           5  Cooperativa de Quesos 'Las Cabras'  Antonio del Valle Saavedra   \n",
      "\n",
      "           ContactTitle                    Address         City    Region  \\\n",
      "0    Purchasing Manager             49 Gilbert St.       London      None   \n",
      "1   Order Administrator             P.O. Box 78934  New Orleans        LA   \n",
      "2  Sales Representative             707 Oxford Rd.    Ann Arbor        MI   \n",
      "3     Marketing Manager  9-8 Sekimai Musashino-shi        Tokyo      None   \n",
      "4  Export Administrator          Calle del Rosal 4       Oviedo  Asturias   \n",
      "\n",
      "  PostalCode Country           Phone             Fax     HomePage  \n",
      "0    EC1 4SD      UK  (171) 555-2222            None         None  \n",
      "1      70117     USA  (100) 555-4822            None  #CAJUN.HTM#  \n",
      "2      48104     USA  (313) 555-5735  (313) 555-3349         None  \n",
      "3        100   Japan  (03) 3555-5011            None         None  \n",
      "4      33007   Spain  (98) 598 76 54            None         None  \n"
     ]
    }
   ],
   "source": [
    "#get dataframe from dictionary\n",
    "Suppliers = df_NorthWind.get(\"Suppliers\")\n",
    "\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if Suppliers is not None:\n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"Suppliers\"] = Suppliers\n",
    "\n",
    "    print(f\" Rows: {len(Suppliers)}\")\n",
    "    print(Suppliers.head())\n",
    "else:\n",
    "    print(\"The table does not exist in database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Person_Person\n",
    "<h4> Bronnen: Person_Person + Employees + Employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MergedBusinessEntityID BusinessEntityID PersonType NameStyle    Title  \\\n",
      "0                          1                1         EM         0     None   \n",
      "1                          2                2         EM         0     None   \n",
      "2                          3                3         EM         0     None   \n",
      "3                          4                4         EM         0     None   \n",
      "4                          5                5         EM         0      Ms.   \n",
      "...                      ...              ...        ...       ...      ...   \n",
      "20051                 200921              921        NaN       NaN  Charles   \n",
      "20052                 200930              930        NaN       NaN      Ann   \n",
      "20053                 200949              949        NaN       NaN   Pamela   \n",
      "20054                 200958              958        NaN       NaN   Thomas   \n",
      "20055                 200992              992        NaN       NaN    Joyce   \n",
      "\n",
      "          LastName Suffix EmailPromotion  \\\n",
      "0         SÃ¡nchez   None              0   \n",
      "1            Duffy   None              1   \n",
      "2       Tamburello   None              0   \n",
      "3          Walters   None              0   \n",
      "4         Erickson   None              0   \n",
      "...            ...    ...            ...   \n",
      "20051      Crowley    NaN            NaN   \n",
      "20052       Taylor    NaN            NaN   \n",
      "20053     Savarino    NaN            NaN   \n",
      "20054       Sisson    NaN            NaN   \n",
      "20055  Butterfield    NaN            NaN   \n",
      "\n",
      "                                     rowguid       ModifiedDate  \\\n",
      "0      {92C4279F-1207-48A3-84484636514EB7E2}  01/07/19 00:00:00   \n",
      "1      {D8763459-8AA8-47CC-AFF7C9079AF79033}  01/24/18 00:00:00   \n",
      "2      {E1A2555E-0828-434B-A33B6F38136A37DE}  11/04/17 00:00:00   \n",
      "3      {F2D7CE06-38B3-4357-805BF4B6B71C01FF}  11/28/17 00:00:00   \n",
      "4      {F3A3F6B4-AE3B-430C-A7549F2231BA6FEF}  12/30/17 00:00:00   \n",
      "...                                      ...                ...   \n",
      "20051                                    NaN                NaN   \n",
      "20052                                    NaN                NaN   \n",
      "20053                                    NaN                NaN   \n",
      "20054                                    NaN                NaN   \n",
      "20055                                    NaN                NaN   \n",
      "\n",
      "               Source PhoneNumber  \n",
      "0      AdventureWorks         NaN  \n",
      "1      AdventureWorks         NaN  \n",
      "2      AdventureWorks         NaN  \n",
      "3      AdventureWorks         NaN  \n",
      "4      AdventureWorks         NaN  \n",
      "...               ...         ...  \n",
      "20051            aenc  6175559425  \n",
      "20052            aenc  4045551515  \n",
      "20053            aenc  3105551857  \n",
      "20054            aenc  7135558390  \n",
      "20055            aenc  6175552232  \n",
      "\n",
      "[20056 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Laden van de datasets (Vervang dit met je eigen DataFrame-imports)\n",
    "Person_Person_df = df_AdventureWorks.get(\"Person_Person\")\n",
    "Employees_df = df_NorthWind.get(\"Employees\")\n",
    "Employee_df = df_aenc.get(\"Employee\")\n",
    "\n",
    "# Voeg 'Source' kolom toe om de herkomst te behouden\n",
    "Person_Person_df[\"Source\"] = \"AdventureWorks\"\n",
    "Employees_df[\"Source\"] = \"Northwind\"\n",
    "Employee_df[\"Source\"] = \"aenc\"\n",
    "\n",
    "# Hernoem kolommen zodat ze consistent zijn met Person_Person\n",
    "Employees_df.rename(columns={\"EmployeeID\": \"BusinessEntityID\", \"HomePhone\": \"PhoneNumber\"}, inplace=True)\n",
    "Employee_df.rename(columns={\"emp_id\": \"BusinessEntityID\", \"phone\": \"PhoneNumber\"}, inplace=True)\n",
    "\n",
    "# Voeg een unieke sleutel toe (MergedBusinessEntityID) om overlaps te voorkomen\n",
    "Person_Person_df[\"MergedBusinessEntityID\"] = Person_Person_df[\"BusinessEntityID\"]\n",
    "Employees_df[\"MergedBusinessEntityID\"] = Employees_df[\"BusinessEntityID\"] + 100000  # Offset voor Northwind\n",
    "Employee_df[\"MergedBusinessEntityID\"] = Employee_df[\"BusinessEntityID\"] + 200000  # Offset voor AENC\n",
    "\n",
    "# Houd alleen de relevante kolommen\n",
    "Person_Person_df = Person_Person_df[[\"MergedBusinessEntityID\", \"BusinessEntityID\", \"PersonType\", \"NameStyle\", \"Title\", \"LastName\", \"Suffix\", \"EmailPromotion\", \"rowguid\",  \"ModifiedDate\", \"Source\"]]\n",
    "Employees_df = Employees_df[[\"MergedBusinessEntityID\", \"BusinessEntityID\", \"Title\", \"LastName\", \"PhoneNumber\", \"Source\"]]\n",
    "Employee_df = Employee_df[[\"MergedBusinessEntityID\", \"BusinessEntityID\", \"emp_fname\", \"emp_lname\", \"PhoneNumber\", \"Source\"]]\n",
    "\n",
    "# Hernoemen van kolommen zodat ze overeenkomen\n",
    "Employees_df.rename(columns={\"Title\": \"Title\", \"LastName\": \"LastName\"}, inplace=True)\n",
    "Employee_df.rename(columns={\"emp_fname\": \"Title\", \"emp_lname\": \"LastName\"}, inplace=True)\n",
    "\n",
    "# Samenvoegen van de tabellen zonder merge (alle data onder elkaar)\n",
    "merged_person = pd.concat([Person_Person_df, Employees_df, Employee_df], ignore_index=True)\n",
    "\n",
    "dfs_sourcedatamodel[\"Person_Person\"] = merged_person\n",
    "\n",
    "\n",
    "# Mapping maken voor toekomstige foreign key updates\n",
    "person_mapping = merged_person[[\"BusinessEntityID\", \"Source\", \"MergedBusinessEntityID\"]]\n",
    "df_mapping[\"person_mapping\"] = person_mapping\n",
    "\n",
    "# Print het resultaat\n",
    "print(merged_person)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: HumanResources_Department\n",
    "<h4> bronnen: HumanResources_Department + Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "   DepartmentID                        Name  \\\n",
      "0             1                 Engineering   \n",
      "1             2                 Tool Design   \n",
      "2             3                       Sales   \n",
      "3             4                   Marketing   \n",
      "4             5                  Purchasing   \n",
      "5             6    Research and Development   \n",
      "6             7                  Production   \n",
      "7             8          Production Control   \n",
      "8             9             Human Resources   \n",
      "9            10                     Finance   \n",
      "10           11        Information Services   \n",
      "11           12            Document Control   \n",
      "12           13           Quality Assurance   \n",
      "13           14  Facilities and Maintenance   \n",
      "14           15      Shipping and Receiving   \n",
      "15           16                   Executive   \n",
      "16          100                       R & D   \n",
      "17          200                       Sales   \n",
      "18          300                     Finance   \n",
      "19          400                   Marketing   \n",
      "20          500                    Shipping   \n",
      "\n",
      "                               GroupName       ModifiedDate          Source  \n",
      "0               Research and Development  04/30/18 00:00:00  AdventureWorks  \n",
      "1               Research and Development  04/30/18 00:00:00  AdventureWorks  \n",
      "2                    Sales and Marketing  04/30/18 00:00:00  AdventureWorks  \n",
      "3                    Sales and Marketing  04/30/18 00:00:00  AdventureWorks  \n",
      "4                   Inventory Management  04/30/18 00:00:00  AdventureWorks  \n",
      "5               Research and Development  04/30/18 00:00:00  AdventureWorks  \n",
      "6                          Manufacturing  04/30/18 00:00:00  AdventureWorks  \n",
      "7                          Manufacturing  04/30/18 00:00:00  AdventureWorks  \n",
      "8   Executive General and Administration  04/30/18 00:00:00  AdventureWorks  \n",
      "9   Executive General and Administration  04/30/18 00:00:00  AdventureWorks  \n",
      "10  Executive General and Administration  04/30/18 00:00:00  AdventureWorks  \n",
      "11                     Quality Assurance  04/30/18 00:00:00  AdventureWorks  \n",
      "12                     Quality Assurance  04/30/18 00:00:00  AdventureWorks  \n",
      "13  Executive General and Administration  04/30/18 00:00:00  AdventureWorks  \n",
      "14                  Inventory Management  04/30/18 00:00:00  AdventureWorks  \n",
      "15  Executive General and Administration  04/30/18 00:00:00  AdventureWorks  \n",
      "16                                  None               None            AENC  \n",
      "17                                  None               None            AENC  \n",
      "18                                  None               None            AENC  \n",
      "19                                  None               None            AENC  \n",
      "20                                  None               None            AENC  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Laden van de datasets (vervang met echte DataFrame-imports)\n",
    "HumanResources_Department_df = df_AdventureWorks.get(\"HumanResources_Department\")\n",
    "Department_df = df_aenc.get(\"Department\")\n",
    "\n",
    "# Voeg 'Source' kolom toe\n",
    "HumanResources_Department_df[\"Source\"] = \"AdventureWorks\"\n",
    "Department_df[\"Source\"] = \"AENC\"\n",
    "\n",
    "# Hernoem kolommen zodat ze consistent zijn\n",
    "Department_df.rename(columns={\"dept_id\": \"DepartmentID\", \"dept_name\": \"Name\"}, inplace=True)\n",
    "\n",
    "# Houd alleen de relevante kolommen\n",
    "HumanResources_Department_df = HumanResources_Department_df[[\"DepartmentID\", \"Name\", \"GroupName\", \"ModifiedDate\", \"Source\"]]\n",
    "Department_df = Department_df[[\"DepartmentID\", \"Name\", \"Source\"]]\n",
    "\n",
    "# Voeg een placeholder toe voor ontbrekende GroupName en ModifiedDate in AENC-data\n",
    "Department_df[\"GroupName\"] = None\n",
    "Department_df[\"ModifiedDate\"] = None\n",
    "\n",
    "# Samenvoegen van de tabellen zonder merge (alle data onder elkaar)\n",
    "merged_departments = pd.concat([HumanResources_Department_df, Department_df], ignore_index=True)\n",
    "\n",
    "dfs_sourcedatamodel[\"HumanResources_Department\"] = merged_departments\n",
    "\n",
    "print(HumanResources_Department_df[\"GroupName\"].str.len().max())  # Check maximale lengte \n",
    "\n",
    "# Print het resultaat\n",
    "print(merged_departments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: HumanResources_Employee\n",
    "<h4> Bronnen: HumanResources_Employee + Employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MergedBusinessEntityID BusinessEntityID                       JobTitle  \\\n",
      "0                          1                1        Chief Executive Officer   \n",
      "1                          2                2  Vice President of Engineering   \n",
      "2                          3                3            Engineering Manager   \n",
      "3                          4                4           Senior Tool Designer   \n",
      "4                          5                5                Design Engineer   \n",
      "...                      ...              ...                            ...   \n",
      "20051                 200921              921                           None   \n",
      "20052                 200930              930                           None   \n",
      "20053                 200949              949                           None   \n",
      "20054                 200958              958                           None   \n",
      "20055                 200992              992                           None   \n",
      "\n",
      "         BirthDate     HireDate Gender   salary ManagerID DepartmentID  \\\n",
      "0       1979-01-29   2019-01-14      M      NaN       NaN           16   \n",
      "1       1981-08-01   2018-01-31      F      NaN       NaN            1   \n",
      "2       1984-11-12   2017-11-11      M      NaN       NaN            1   \n",
      "3       1984-12-23   2017-12-05      M      NaN       NaN            2   \n",
      "4       1962-09-27   2018-01-06      F      NaN       NaN            1   \n",
      "...            ...          ...    ...      ...       ...          ...   \n",
      "20051  11-Sep-1987  22-Apr-2019      M  41700.0    200703          500   \n",
      "20052  06-Jun-1989  08-May-2019      F  46890.0    200902          200   \n",
      "20053  28-Jul-1997  08-May-2019      F  72300.0    200902          200   \n",
      "20054  02-Oct-1996  16-Jul-2019      M  42100.0    200501          100   \n",
      "20055  15-Apr-1987  13-Aug-2019      F  34011.0    201576          400   \n",
      "\n",
      "               Source  \n",
      "0      AdventureWorks  \n",
      "1      AdventureWorks  \n",
      "2      AdventureWorks  \n",
      "3      AdventureWorks  \n",
      "4      AdventureWorks  \n",
      "...               ...  \n",
      "20051            AENC  \n",
      "20052            AENC  \n",
      "20053            AENC  \n",
      "20054            AENC  \n",
      "20055            AENC  \n",
      "\n",
      "[20056 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Laden van de datasets (Vervang dit met je eigen DataFrame-imports)\n",
    "Person_Person_df = df_AdventureWorks.get(\"Person_Person\")\n",
    "Employees_df2 = df_NorthWind.get(\"Employees\")\n",
    "Employee_df2 = df_aenc.get(\"Employee\")\n",
    "HumanResources_Employee_df = df_AdventureWorks.get(\"HumanResources_Employee\")  # Nieuwe tabel\n",
    "\n",
    "# Voeg 'Source' kolom toe om de herkomst te behouden\n",
    "Person_Person_df[\"Source\"] = \"AdventureWorks\"\n",
    "Employees_df2[\"Source\"] = \"NorthWind\"\n",
    "Employee_df2[\"Source\"] = \"AENC\"\n",
    "\n",
    "# Hernoem kolommen zodat ze consistent zijn met Person_Person\n",
    "Employees_df2.rename(columns={\"EmployeeID\": \"BusinessEntityID\", \"Title\": \"JobTitle\", \"BirthDate\": \"BirthDate\", \"HireDate\": \"HireDate\", \"TitleOfCourtesy\": \"Gender\"}, inplace=True)\n",
    "Employee_df2.rename(columns={\"emp_id\": \"BusinessEntityID\", \"start_date\": \"HireDate\", \"birth_date\": \"BirthDate\", \"sex\": \"Gender\", \"salary\": \"salary\", \"manager_id\": \"ManagerID\",\"dept_id\":\"DepartmentID\"}, inplace=True)\n",
    "\n",
    "# Voeg een unieke sleutel toe (MergedBusinessEntityID) om overlaps te voorkomen\n",
    "Person_Person_df[\"MergedBusinessEntityID\"] = Person_Person_df[\"BusinessEntityID\"]\n",
    "Employees_df2[\"MergedBusinessEntityID\"] = Employees_df2[\"BusinessEntityID\"] + 100000  # Offset voor Northwind\n",
    "Employee_df2[\"MergedBusinessEntityID\"] = Employee_df2[\"BusinessEntityID\"] + 200000  # Offset voor AENC\n",
    "\n",
    "# Voeg lege waarden toe voor ontbrekende kolommen\n",
    "Employee_df2[\"JobTitle\"] = None\n",
    "\n",
    "# Mapping maken voor ManagerID verwijzing\n",
    "manager_mapping = Employee_df2[[\"BusinessEntityID\", \"MergedBusinessEntityID\"]].copy()\n",
    "manager_mapping.rename(columns={\"BusinessEntityID\": \"OldManagerID\", \"MergedBusinessEntityID\": \"NewManagerID\"}, inplace=True)\n",
    "\n",
    "# Houd alleen de relevante kolommen\n",
    "Person_Person_df = Person_Person_df[[\"MergedBusinessEntityID\", \"BusinessEntityID\", \"Source\"]]\n",
    "Employees_df2 = Employees_df2[[\"MergedBusinessEntityID\", \"BusinessEntityID\", \"JobTitle\", \"BirthDate\", \"HireDate\", \"Gender\", \"Source\"]]\n",
    "Employee_df2 = Employee_df2[[\"MergedBusinessEntityID\", \"BusinessEntityID\", \"JobTitle\", \"BirthDate\", \"HireDate\", \"Gender\", \"salary\", \"ManagerID\", \"Source\", \"DepartmentID\"]]\n",
    "\n",
    "# Merge managerID correct op basis van de mapping\n",
    "Employee_df2 = Employee_df2.merge(manager_mapping, how=\"left\", left_on=\"ManagerID\", right_on=\"OldManagerID\")\n",
    "Employee_df2.drop(columns=[\"OldManagerID\", \"ManagerID\"], inplace=True)\n",
    "Employee_df2.rename(columns={\"NewManagerID\": \"ManagerID\"}, inplace=True)\n",
    "\n",
    "# Merge Person_Person met HumanResources_Employee op BusinessEntityID\n",
    "Person_Person_df = Person_Person_df.merge(\n",
    "    HumanResources_Employee_df[[\"BusinessEntityID\", \"DepartmentID\", \"BirthDate\", \"HireDate\", \"JobTitle\", \"Gender\"]],\n",
    "    on=\"BusinessEntityID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Samenvoegen van de tabellen zonder concat (één enkele tabel)\n",
    "merged_human_resources_Employee = pd.concat([Person_Person_df, Employees_df2, Employee_df2], ignore_index=True)\n",
    "\n",
    "# Pas de volgorde van de kolommen aan\n",
    "column_order = [\"MergedBusinessEntityID\", \"BusinessEntityID\", \"JobTitle\", \"BirthDate\", \"HireDate\", \"Gender\", \"salary\", \"ManagerID\", \"DepartmentID\", \"Source\"]\n",
    "merged_human_resources_Employee = merged_human_resources_Employee[column_order]\n",
    "\n",
    "dfs_sourcedatamodel[\"HumanResources_Employee\"] = merged_human_resources_Employee\n",
    "\n",
    "# Mapping maken voor toekomstige foreign key updates\n",
    "employee_mapping = merged_human_resources_Employee[[\"BusinessEntityID\", \"Source\", \"MergedBusinessEntityID\"]]\n",
    "df_mapping[\"employee_mapping\"] = employee_mapping\n",
    "\n",
    "# Print het resultaat\n",
    "print(merged_human_resources_Employee)\n",
    "\n",
    "merged_human_resources_Employee[\"salary\"] = merged_human_resources_Employee[\"salary\"].fillna(0).astype(float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Table: Person_Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 19614\n",
      "  AddressID          AddressLine1 AddressLine2     City StateProvinceID  \\\n",
      "0         1         1970 Napa Ct.         None  Bothell              79   \n",
      "1         2    9833 Mt. Dias Blv.         None  Bothell              79   \n",
      "2         3  7484 Roundtree Drive         None  Bothell              79   \n",
      "3         4      9539 Glenside Dr         None  Bothell              79   \n",
      "4         5         1226 Shoe St.         None  Bothell              79   \n",
      "\n",
      "  PostalCode BusinessEntityID  \n",
      "0      98011               12  \n",
      "1      98011              123  \n",
      "2      98011              285  \n",
      "3      98011              251  \n",
      "4      98011              124  \n"
     ]
    }
   ],
   "source": [
    "#get dataframe from dictionary\n",
    "Person_Adress_Df = df_AdventureWorks.get(\"Person_Address\")\n",
    "column_order = [\"AddressID\", \"AddressLine1\", \"AddressLine2\", \"City\", \"StateProvinceID\", \"PostalCode\",\"BusinessEntityID\"]\n",
    "Person_Adress_Df = Person_Adress_Df[column_order]\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if Person_Adress_Df is not None:\n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"Person_Address\"] = Person_Adress_Df\n",
    "\n",
    "    print(f\"Rows: {len(Person_Adress_Df)}\")\n",
    "    print(Person_Adress_Df.head())\n",
    "else:\n",
    "    print(\"The table does not exist in database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Shippers\n",
    "<h4> bronnen: Shippers + Orders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rows: 3\n",
      "   ShipperID       CompanyName           Phone\n",
      "0          1    Speedy Express  (503) 555-9831\n",
      "1          2    United Package  (503) 555-3199\n",
      "2          3  Federal Shipping  (503) 555-9931\n"
     ]
    }
   ],
   "source": [
    "#get dataframe from dictionary\n",
    "Shippers = df_NorthWind.get(\"Shippers\")\n",
    "\n",
    "# Check if the DataFrame exists\n",
    "if Shippers is not None:\n",
    "    # Add the DataFrame to the sourcedatamodel dictionary\n",
    "    dfs_sourcedatamodel[\"Shippers\"] = Shippers\n",
    "\n",
    "    print(f\" Rows: {len(Shippers)}\")\n",
    "    print(Shippers.head())\n",
    "else:\n",
    "    print(\"The table does not exist in database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> table: Sales_SalesOrderHeader\n",
    "<h4> Bronnen: Sales_SalesOrderHeader + Orders + Sales_Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SalesOrderID RevisionNumber          OrderDate            DueDate  \\\n",
      "0        43659              8  05/31/21 00:00:00  06/12/21 00:00:00   \n",
      "1        43660              8  05/31/21 00:00:00  06/12/21 00:00:00   \n",
      "2        43661              8  05/31/21 00:00:00  06/12/21 00:00:00   \n",
      "3        43662              8  05/31/21 00:00:00  06/12/21 00:00:00   \n",
      "4        43663              8  05/31/21 00:00:00  06/12/21 00:00:00   \n",
      "\n",
      "            ShipDate  CustomerID SalesPersonID TerritoryID    SubTotal  \\\n",
      "0  06/07/21 00:00:00       19527           279           5  20565.6206   \n",
      "1  06/07/21 00:00:00       19374           279           5   1294.2529   \n",
      "2  06/07/21 00:00:00       19436           282           6  32726.4786   \n",
      "3  06/07/21 00:00:00       19696           282           6  28832.5289   \n",
      "4  06/07/21 00:00:00       19267           276           4    419.4589   \n",
      "\n",
      "  ShipVia ShipCountry ShipRegion ShipCity          Source  \n",
      "0    None        None       None     None  AdventureWorks  \n",
      "1    None        None       None     None  AdventureWorks  \n",
      "2    None        None       None     None  AdventureWorks  \n",
      "3    None        None       None     None  AdventureWorks  \n",
      "4    None        None       None     None  AdventureWorks  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  1. Laad de datasets \n",
    "sales_adventureworks_df = df_AdventureWorks.get(\"Sales_SalesOrderHeader\")\n",
    "northwind_orders_df = df_NorthWind.get(\"Orders\")\n",
    "aenc_sales_order_df = df_aenc.get(\"Sales_Order\")\n",
    "\n",
    "#  2. Voeg Source toe aan elke DataFrame \n",
    "sales_adventureworks_df[\"Source\"] = \"AdventureWorks\"\n",
    "northwind_orders_df[\"Source\"] = \"NorthWind\"\n",
    "aenc_sales_order_df[\"Source\"] = \"AENC\"\n",
    "\n",
    "#  3. Hernoem kolommen voor consistentie \n",
    "northwind_orders_df.rename(columns={\n",
    "    \"OrderID\": \"SalesOrderID\",\n",
    "    \"OrderDate\": \"OrderDate\",\n",
    "    \"ShippedDate\": \"ShipDate\",\n",
    "    \"CustomerID\": \"CustomerID\",\n",
    "    \"EmployeeID\": \"SalesPersonID\",\n",
    "    \"Freight\": \"SubTotal\",\n",
    "    \"ShipVia\": \"ShipVia\",\n",
    "    \"ShipCountry\": \"ShipCountry\",\n",
    "    \"ShipRegion\": \"ShipRegion\",\n",
    "    \"ShipCity\": \"ShipCity\"\n",
    "}, inplace=True)\n",
    "\n",
    "aenc_sales_order_df.rename(columns={\n",
    "    \"id\": \"SalesOrderID\",\n",
    "    \"order_date\": \"OrderDate\",\n",
    "    \"cust_id\": \"CustomerID\",\n",
    "    \"sales_rep\": \"SalesPersonID\",\n",
    "    \"region\": \"ShipRegion\"\n",
    "}, inplace=True)\n",
    "\n",
    "#  4. Zorg dat CustomerID overal een string is \n",
    "sales_adventureworks_df[\"CustomerID\"] = sales_adventureworks_df[\"CustomerID\"].astype(str)\n",
    "northwind_orders_df[\"CustomerID\"] = northwind_orders_df[\"CustomerID\"].astype(str)\n",
    "aenc_sales_order_df[\"CustomerID\"] = aenc_sales_order_df[\"CustomerID\"].astype(str)\n",
    "\n",
    "# Ook in de customer_mapping DataFrame\n",
    "customer_mapping[\"CustomerID\"] = customer_mapping[\"CustomerID\"].astype(str)\n",
    "\n",
    "#  5. Ontbrekende kolommen aanvullen met None \n",
    "for df in [sales_adventureworks_df, northwind_orders_df, aenc_sales_order_df]:\n",
    "    for col in [\"RevisionNumber\", \"TerritoryID\", \"SubTotal\", \"DueDate\",\n",
    "                \"ShipDate\", \"ShipVia\", \"ShipCountry\", \"ShipRegion\", \"ShipCity\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "#  6. Selecteer en orden de relevante kolommen \n",
    "cols = [\n",
    "    \"SalesOrderID\", \"RevisionNumber\", \"OrderDate\", \"DueDate\", \"ShipDate\", \n",
    "    \"CustomerID\", \"SalesPersonID\", \"TerritoryID\", \"SubTotal\", \n",
    "    \"ShipVia\", \"ShipCountry\", \"ShipRegion\", \"ShipCity\", \"Source\"\n",
    "]\n",
    "\n",
    "sales_adventureworks_df = sales_adventureworks_df[cols]\n",
    "northwind_orders_df = northwind_orders_df[cols]\n",
    "aenc_sales_order_df = aenc_sales_order_df[cols]\n",
    "\n",
    "#  7. Concateneer de drie DataFrames \n",
    "merged_sales_salesOrderHeader = pd.concat(\n",
    "    [sales_adventureworks_df, northwind_orders_df, aenc_sales_order_df], \n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "#  8. CustomerID bijwerken via customer_mapping \n",
    "# Hier nemen we aan dat 'customer_mapping' al bestaat, met kolommen [\"CustomerID\", \"Source\", \"MergedCustomerID\"].\n",
    "merged_sales_salesOrderHeader = merged_sales_salesOrderHeader.merge(\n",
    "    customer_mapping,\n",
    "    on=[\"CustomerID\", \"Source\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Vervang de CustomerID door MergedCustomerID\n",
    "merged_sales_salesOrderHeader[\"CustomerID\"] = merged_sales_salesOrderHeader[\"MergedCustomerID\"]\n",
    "merged_sales_salesOrderHeader.drop(columns=[\"MergedCustomerID\"], inplace=True)\n",
    "\n",
    "#  9. SalesPersonID bijwerken via employee_mapping \n",
    "# Hier nemen we aan dat 'employee_mapping' al bestaat, met kolommen [\"BusinessEntityID\", \"Source\", \"MergedBusinessEntityID\"].\n",
    "merged_sales_salesOrderHeader = merged_sales_salesOrderHeader.merge(\n",
    "    employee_mapping,\n",
    "    left_on=[\"SalesPersonID\", \"Source\"],\n",
    "    right_on=[\"BusinessEntityID\", \"Source\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_emp\")\n",
    ")\n",
    "\n",
    "# Vervang SalesPersonID door de gemapte MergedBusinessEntityID\n",
    "merged_sales_salesOrderHeader[\"SalesPersonID\"] = merged_sales_salesOrderHeader[\"MergedBusinessEntityID\"]\n",
    "merged_sales_salesOrderHeader.drop(columns=[\"BusinessEntityID\", \"MergedBusinessEntityID\"], inplace=True)\n",
    "\n",
    "#  10. Sla op in het data model en exporteer \n",
    "dfs_sourcedatamodel[\"Sales_SalesOrderHeader\"] = merged_sales_salesOrderHeader\n",
    "print(merged_sales_salesOrderHeader.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Table: Sales_SalesOrderDetail\n",
    "<h4> Bronnen: Sales_SalesOrderDetail + OrderDetails + sales_order_item + product(aenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SalesOrderID SalesOrderDetailID OrderQty  ProductID UnitPrice  \\\n",
      "0        43659                  1        1        281  2024.994   \n",
      "1        43659                  2        3        282  2024.994   \n",
      "2        43659                  3        1        283  2024.994   \n",
      "3        43659                  4        1        276  2039.994   \n",
      "4        43659                  5        1        277  2039.994   \n",
      "\n",
      "  UnitPriceDiscount LineTotal          Source  \n",
      "0               0.0  2024.994  AdventureWorks  \n",
      "1               0.0  6074.982  AdventureWorks  \n",
      "2               0.0  2024.994  AdventureWorks  \n",
      "3               0.0  2039.994  AdventureWorks  \n",
      "4               0.0  2039.994  AdventureWorks  \n"
     ]
    }
   ],
   "source": [
    "# 1. Laad de datasets \n",
    "Sales_SalesOrderDetail = df_AdventureWorks.get(\"Sales_SalesOrderDetail\")\n",
    "Sales_Order_Item = df_aenc.get(\"Sales_Order_Item\")\n",
    "OrderDetails = df_NorthWind.get(\"OrderDetails\")\n",
    "df_product2 = df_aenc.get(\"Product\")  \n",
    "\n",
    "df_product2.rename(columns={\"id\": \"ProductID\"}, inplace=True)\n",
    "\n",
    "# 2. Voeg Source toe aan elke DataFrame \n",
    "Sales_SalesOrderDetail[\"Source\"] = \"AdventureWorks\"\n",
    "Sales_Order_Item[\"Source\"] = \"AENC\"\n",
    "OrderDetails[\"Source\"] = \"NorthWind\"\n",
    "\n",
    "# 3. Verwerk de AdventureWorks data \n",
    "Sales_SalesOrderDetail = Sales_SalesOrderDetail.copy()\n",
    "Sales_SalesOrderDetail = Sales_SalesOrderDetail[[\n",
    "    \"SalesOrderID\", \"SalesOrderDetailID\", \"OrderQty\", \"ProductID\", \n",
    "    \"UnitPrice\", \"UnitPriceDiscount\", \"LineTotal\", \"Source\"\n",
    "]]\n",
    "\n",
    "# 4. Verwerk de AENC data \n",
    "Sales_Order_Item = Sales_Order_Item.copy()\n",
    "Sales_Order_Item.rename(columns={\n",
    "    \"id\": \"SalesOrderID\",\n",
    "    \"line_id\": \"SalesOrderDetailID\",\n",
    "    \"prod_id\": \"ProductID\",\n",
    "    \"quantity\": \"OrderQty\"\n",
    "}, inplace=True)\n",
    "\n",
    "if df_product2 is not None:\n",
    "    Sales_Order_Item = Sales_Order_Item.merge(df_product2[[\"ProductID\", \"unit_price\"]], on=\"ProductID\", how=\"left\")\n",
    "    Sales_Order_Item.rename(columns={\"unit_price\": \"UnitPrice\"}, inplace=True)\n",
    "else:\n",
    "    print(\"The table does not exist in database.\")\n",
    "\n",
    "# 5. Verwerk de NorthWind data \n",
    "OrderDetails = OrderDetails.copy()\n",
    "OrderDetails.rename(columns={\n",
    "    \"OrderID\": \"SalesOrderID\",\n",
    "    \"Quantity\": \"OrderQty\",\n",
    "    \"Discount\": \"UnitPriceDiscount\"\n",
    "}, inplace=True)\n",
    "\n",
    "OrderDetails[\"SalesOrderDetailID\"] = OrderDetails.groupby(\"SalesOrderID\").cumcount() + 1\n",
    "OrderDetails[\"LineTotal\"] = None\n",
    "OrderDetails = OrderDetails[[\n",
    "    \"SalesOrderID\", \"SalesOrderDetailID\", \"OrderQty\", \"ProductID\", \n",
    "    \"UnitPrice\", \"UnitPriceDiscount\", \"LineTotal\", \"Source\"\n",
    "]]\n",
    "\n",
    "# 6. Combineer de drie bronnen \n",
    "merged_orderdetail = pd.concat([Sales_SalesOrderDetail, Sales_Order_Item, OrderDetails], ignore_index=True)\n",
    "\n",
    "# 7. Werk de ProductID bij via product_mapping \n",
    "merged_orderdetail = merged_orderdetail.merge(\n",
    "    product_mapping,\n",
    "    on=[\"ProductID\", \"Source\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "merged_orderdetail[\"ProductID\"] = merged_orderdetail[\"MergedID\"]\n",
    "merged_orderdetail.drop(columns=[\"MergedID\"], inplace=True)\n",
    "\n",
    "# 8. Verwijder de kolom ShipDate als die bestaat\n",
    "if \"ship_date\" in merged_orderdetail.columns:\n",
    "    merged_orderdetail = merged_orderdetail.drop(columns=[\"ship_date\"])\n",
    "\n",
    "# 9. Sla het resultaat op in het datamodel \n",
    "dfs_sourcedatamodel[\"Sales_SalesOrderDetail\"] = merged_orderdetail\n",
    "\n",
    "# 10. Print preview\n",
    "print(merged_orderdetail.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Vullen SDM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production_ProductCategory: (12, 7)\n",
      "Production_Product: (591, 34)\n",
      "Purchasing_Vendor: (104, 8)\n",
      "Sales_Store: (701, 5)\n",
      "EmployeeTerritories: (49, 2)\n",
      "Territories: (53, 3)\n",
      "Region: (4, 2)\n",
      "Bonus: (33, 3)\n",
      "Sales_Customer: (20037, 10)\n",
      "Sales_SalesTerritory: (10, 10)\n",
      "Purchasing_PurchaseOrderHeader: (4012, 13)\n",
      "Purchasing_PurchaseOrderDetail: (8845, 12)\n",
      "Suppliers: (29, 12)\n",
      "Person_Person: (20056, 12)\n",
      "HumanResources_Department: (21, 5)\n",
      "HumanResources_Employee: (20056, 10)\n",
      "Person_Address: (19614, 7)\n",
      "Shippers: (3, 3)\n",
      "Sales_SalesOrderHeader: (32945, 14)\n",
      "Sales_SalesOrderDetail: (124575, 8)\n"
     ]
    }
   ],
   "source": [
    "for tabel in dfs_sourcedatamodel:\n",
    "    print(f\"{tabel}: {dfs_sourcedatamodel[tabel].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Connectie leggen SDM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verbindingsgegevens\n",
    "server = '127.0.0.1'        \n",
    "port = '1433'               \n",
    "database2 = 'SDMProject'         \n",
    "username = 'SA'             \n",
    "password = 'iDTyjZx7dRL4'  \n",
    "\n",
    "# Connection string\n",
    "connection_string2 = (\n",
    "    f\"DRIVER={{ODBC Driver 17 for SQL Server}};\"\n",
    "    f\"SERVER={server},{port};\"\n",
    "    f\"DATABASE={database2};\"\n",
    "    f\"UID={username};\"\n",
    "    f\"PWD={password};\"\n",
    "    \"TrustServerCertificate=yes;\"\n",
    "    \"Timeout=30;\"\n",
    ")\n",
    "\n",
    "# Maak verbinding met de database\n",
    "conn = pyodbc.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Haal alle tabellen op``\n",
    "cursor.execute(\"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE'\")\n",
    "tables = [row.TABLE_NAME for row in cursor.fetchall()]\n",
    "\n",
    "\n",
    "# Sluit de verbinding\n",
    "conn.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Converteer datatypen met datums naar DATETIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Geconverteerd: Production_ProductCategory.ModifiedDate\n",
      "✅ Geconverteerd: Production_Product.SellStartDate\n",
      "✅ Geconverteerd: Production_Product.SellEndDate\n",
      "✅ Geconverteerd: Production_Product.ModifiedDate\n",
      "✅ Geconverteerd: Purchasing_Vendor.ModifiedDate\n",
      "✅ Geconverteerd: Sales_Store.ModifiedDate\n",
      "✅ Geconverteerd: Bonus.bonus_date\n",
      "✅ Geconverteerd: Sales_Customer.ModifiedDate\n",
      "✅ Geconverteerd: Sales_SalesTerritory.ModifiedDate\n",
      "✅ Geconverteerd: Purchasing_PurchaseOrderHeader.OrderDate\n",
      "✅ Geconverteerd: Purchasing_PurchaseOrderHeader.ShipDate\n",
      "✅ Geconverteerd: Purchasing_PurchaseOrderHeader.ModifiedDate\n",
      "✅ Geconverteerd: Purchasing_PurchaseOrderDetail.DueDate\n",
      "✅ Geconverteerd: Purchasing_PurchaseOrderDetail.ModifiedDate\n",
      "✅ Geconverteerd: Person_Person.ModifiedDate\n",
      "✅ Geconverteerd: HumanResources_Department.ModifiedDate\n",
      "✅ Geconverteerd: HumanResources_Employee.BirthDate\n",
      "✅ Geconverteerd: HumanResources_Employee.HireDate\n",
      "✅ Geconverteerd: Sales_SalesOrderHeader.OrderDate\n",
      "✅ Geconverteerd: Sales_SalesOrderHeader.DueDate\n",
      "✅ Geconverteerd: Sales_SalesOrderHeader.ShipDate\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def convert_all_dates(dw):\n",
    "    date_keywords = [\"date\", \"time\"]  # Zoek naar deze woorden in kolomnamen\n",
    "    \n",
    "    for table_name, df in dw.items():\n",
    "        for col in df.columns:\n",
    "            if any(keyword in col.lower() for keyword in date_keywords):  # Check op 'date' of 'time'\n",
    "                try:\n",
    "                    df[col] = pd.to_datetime(df[col], errors='coerce')  # Converteer naar datetime\n",
    "                    print(f\"✅ Geconverteerd: {table_name}.{col}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Fout bij converteren van {col} in {table_name}: {e}\")\n",
    "    \n",
    "    return dw\n",
    "\n",
    "# Pas de functie toe op je DataFrame-collectie\n",
    "dfs_sourcedatamodel = convert_all_dates(dfs_sourcedatamodel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Vullen van database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Uitschakelen van FOREIGN KEY constraints...\n",
      "\n",
      "Bezig met uploaden van tabel: Production_ProductCategory...\n",
      "  ✅ Batch 1 geüpload (12 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Production_Product...\n",
      "  ✅ Batch 1 geüpload (591 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Purchasing_Vendor...\n",
      "  ✅ Batch 1 geüpload (104 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Sales_Store...\n",
      "  ✅ Batch 1 geüpload (701 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: EmployeeTerritories...\n",
      "  ✅ Batch 1 geüpload (49 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Territories...\n",
      "  ✅ Batch 1 geüpload (53 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Region...\n",
      "  ✅ Batch 1 geüpload (4 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Bonus...\n",
      "  ✅ Batch 1 geüpload (33 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Sales_Customer...\n",
      "  ✅ Batch 1 geüpload (1000 rijen)\n",
      "  ✅ Batch 2 geüpload (1000 rijen)\n",
      "  ✅ Batch 3 geüpload (1000 rijen)\n",
      "  ✅ Batch 4 geüpload (1000 rijen)\n",
      "  ✅ Batch 5 geüpload (1000 rijen)\n",
      "  ✅ Batch 6 geüpload (1000 rijen)\n",
      "  ✅ Batch 7 geüpload (1000 rijen)\n",
      "  ✅ Batch 8 geüpload (1000 rijen)\n",
      "  ✅ Batch 9 geüpload (1000 rijen)\n",
      "  ✅ Batch 10 geüpload (1000 rijen)\n",
      "  ✅ Batch 11 geüpload (1000 rijen)\n",
      "  ✅ Batch 12 geüpload (1000 rijen)\n",
      "  ✅ Batch 13 geüpload (1000 rijen)\n",
      "  ✅ Batch 14 geüpload (1000 rijen)\n",
      "  ✅ Batch 15 geüpload (1000 rijen)\n",
      "  ✅ Batch 16 geüpload (1000 rijen)\n",
      "  ✅ Batch 17 geüpload (1000 rijen)\n",
      "  ✅ Batch 18 geüpload (1000 rijen)\n",
      "  ✅ Batch 19 geüpload (1000 rijen)\n",
      "  ✅ Batch 20 geüpload (1000 rijen)\n",
      "  ✅ Batch 21 geüpload (37 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Sales_SalesTerritory...\n",
      "  ✅ Batch 1 geüpload (10 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Purchasing_PurchaseOrderHeader...\n",
      "  ✅ Batch 1 geüpload (1000 rijen)\n",
      "  ✅ Batch 2 geüpload (1000 rijen)\n",
      "  ✅ Batch 3 geüpload (1000 rijen)\n",
      "  ✅ Batch 4 geüpload (1000 rijen)\n",
      "  ✅ Batch 5 geüpload (12 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Purchasing_PurchaseOrderDetail...\n",
      "  ✅ Batch 1 geüpload (1000 rijen)\n",
      "  ✅ Batch 2 geüpload (1000 rijen)\n",
      "  ✅ Batch 3 geüpload (1000 rijen)\n",
      "  ✅ Batch 4 geüpload (1000 rijen)\n",
      "  ✅ Batch 5 geüpload (1000 rijen)\n",
      "  ✅ Batch 6 geüpload (1000 rijen)\n",
      "  ✅ Batch 7 geüpload (1000 rijen)\n",
      "  ✅ Batch 8 geüpload (1000 rijen)\n",
      "  ✅ Batch 9 geüpload (845 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Suppliers...\n",
      "  ✅ Batch 1 geüpload (29 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Person_Person...\n",
      "  ✅ Batch 1 geüpload (1000 rijen)\n",
      "  ✅ Batch 2 geüpload (1000 rijen)\n",
      "  ✅ Batch 3 geüpload (1000 rijen)\n",
      "  ✅ Batch 4 geüpload (1000 rijen)\n",
      "  ✅ Batch 5 geüpload (1000 rijen)\n",
      "  ✅ Batch 6 geüpload (1000 rijen)\n",
      "  ✅ Batch 7 geüpload (1000 rijen)\n",
      "  ✅ Batch 8 geüpload (1000 rijen)\n",
      "  ✅ Batch 9 geüpload (1000 rijen)\n",
      "  ✅ Batch 10 geüpload (1000 rijen)\n",
      "  ✅ Batch 11 geüpload (1000 rijen)\n",
      "  ✅ Batch 12 geüpload (1000 rijen)\n",
      "  ✅ Batch 13 geüpload (1000 rijen)\n",
      "  ✅ Batch 14 geüpload (1000 rijen)\n",
      "  ✅ Batch 15 geüpload (1000 rijen)\n",
      "  ✅ Batch 16 geüpload (1000 rijen)\n",
      "  ✅ Batch 17 geüpload (1000 rijen)\n",
      "  ✅ Batch 18 geüpload (1000 rijen)\n",
      "  ✅ Batch 19 geüpload (1000 rijen)\n",
      "  ✅ Batch 20 geüpload (1000 rijen)\n",
      "  ✅ Batch 21 geüpload (56 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: HumanResources_Department...\n",
      "  ✅ Batch 1 geüpload (21 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: HumanResources_Employee...\n",
      "  ✅ Batch 1 geüpload (1000 rijen)\n",
      "  ✅ Batch 2 geüpload (1000 rijen)\n",
      "  ✅ Batch 3 geüpload (1000 rijen)\n",
      "  ✅ Batch 4 geüpload (1000 rijen)\n",
      "  ✅ Batch 5 geüpload (1000 rijen)\n",
      "  ✅ Batch 6 geüpload (1000 rijen)\n",
      "  ✅ Batch 7 geüpload (1000 rijen)\n",
      "  ✅ Batch 8 geüpload (1000 rijen)\n",
      "  ✅ Batch 9 geüpload (1000 rijen)\n",
      "  ✅ Batch 10 geüpload (1000 rijen)\n",
      "  ✅ Batch 11 geüpload (1000 rijen)\n",
      "  ✅ Batch 12 geüpload (1000 rijen)\n",
      "  ✅ Batch 13 geüpload (1000 rijen)\n",
      "  ✅ Batch 14 geüpload (1000 rijen)\n",
      "  ✅ Batch 15 geüpload (1000 rijen)\n",
      "  ✅ Batch 16 geüpload (1000 rijen)\n",
      "  ✅ Batch 17 geüpload (1000 rijen)\n",
      "  ✅ Batch 18 geüpload (1000 rijen)\n",
      "  ✅ Batch 19 geüpload (1000 rijen)\n",
      "  ✅ Batch 20 geüpload (1000 rijen)\n",
      "  ✅ Batch 21 geüpload (56 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Person_Address...\n",
      "  ✅ Batch 1 geüpload (1000 rijen)\n",
      "  ✅ Batch 2 geüpload (1000 rijen)\n",
      "  ✅ Batch 3 geüpload (1000 rijen)\n",
      "  ✅ Batch 4 geüpload (1000 rijen)\n",
      "  ✅ Batch 5 geüpload (1000 rijen)\n",
      "  ✅ Batch 6 geüpload (1000 rijen)\n",
      "  ✅ Batch 7 geüpload (1000 rijen)\n",
      "  ✅ Batch 8 geüpload (1000 rijen)\n",
      "  ✅ Batch 9 geüpload (1000 rijen)\n",
      "  ✅ Batch 10 geüpload (1000 rijen)\n",
      "  ✅ Batch 11 geüpload (1000 rijen)\n",
      "  ✅ Batch 12 geüpload (1000 rijen)\n",
      "  ✅ Batch 13 geüpload (1000 rijen)\n",
      "  ✅ Batch 14 geüpload (1000 rijen)\n",
      "  ✅ Batch 15 geüpload (1000 rijen)\n",
      "  ✅ Batch 16 geüpload (1000 rijen)\n",
      "  ✅ Batch 17 geüpload (1000 rijen)\n",
      "  ✅ Batch 18 geüpload (1000 rijen)\n",
      "  ✅ Batch 19 geüpload (1000 rijen)\n",
      "  ✅ Batch 20 geüpload (614 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Shippers...\n",
      "  ✅ Batch 1 geüpload (3 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Sales_SalesOrderHeader...\n",
      "  ✅ Batch 1 geüpload (1000 rijen)\n",
      "  ✅ Batch 2 geüpload (1000 rijen)\n",
      "  ✅ Batch 3 geüpload (1000 rijen)\n",
      "  ✅ Batch 4 geüpload (1000 rijen)\n",
      "  ✅ Batch 5 geüpload (1000 rijen)\n",
      "  ✅ Batch 6 geüpload (1000 rijen)\n",
      "  ✅ Batch 7 geüpload (1000 rijen)\n",
      "  ✅ Batch 8 geüpload (1000 rijen)\n",
      "  ✅ Batch 9 geüpload (1000 rijen)\n",
      "  ✅ Batch 10 geüpload (1000 rijen)\n",
      "  ✅ Batch 11 geüpload (1000 rijen)\n",
      "  ✅ Batch 12 geüpload (1000 rijen)\n",
      "  ✅ Batch 13 geüpload (1000 rijen)\n",
      "  ✅ Batch 14 geüpload (1000 rijen)\n",
      "  ✅ Batch 15 geüpload (1000 rijen)\n",
      "  ✅ Batch 16 geüpload (1000 rijen)\n",
      "  ✅ Batch 17 geüpload (1000 rijen)\n",
      "  ✅ Batch 18 geüpload (1000 rijen)\n",
      "  ✅ Batch 19 geüpload (1000 rijen)\n",
      "  ✅ Batch 20 geüpload (1000 rijen)\n",
      "  ✅ Batch 21 geüpload (1000 rijen)\n",
      "  ✅ Batch 22 geüpload (1000 rijen)\n",
      "  ✅ Batch 23 geüpload (1000 rijen)\n",
      "  ✅ Batch 24 geüpload (1000 rijen)\n",
      "  ✅ Batch 25 geüpload (1000 rijen)\n",
      "  ✅ Batch 26 geüpload (1000 rijen)\n",
      "  ✅ Batch 27 geüpload (1000 rijen)\n",
      "  ✅ Batch 28 geüpload (1000 rijen)\n",
      "  ✅ Batch 29 geüpload (1000 rijen)\n",
      "  ✅ Batch 30 geüpload (1000 rijen)\n",
      "  ✅ Batch 31 geüpload (1000 rijen)\n",
      "  ✅ Batch 32 geüpload (1000 rijen)\n",
      "  ✅ Batch 33 geüpload (945 rijen)\n",
      "\n",
      "Bezig met uploaden van tabel: Sales_SalesOrderDetail...\n",
      "  ✅ Batch 1 geüpload (1000 rijen)\n",
      "  ✅ Batch 2 geüpload (1000 rijen)\n",
      "  ✅ Batch 3 geüpload (1000 rijen)\n",
      "  ✅ Batch 4 geüpload (1000 rijen)\n",
      "  ✅ Batch 5 geüpload (1000 rijen)\n",
      "  ✅ Batch 6 geüpload (1000 rijen)\n",
      "  ✅ Batch 7 geüpload (1000 rijen)\n",
      "  ✅ Batch 8 geüpload (1000 rijen)\n",
      "  ✅ Batch 9 geüpload (1000 rijen)\n",
      "  ✅ Batch 10 geüpload (1000 rijen)\n",
      "  ✅ Batch 11 geüpload (1000 rijen)\n",
      "  ✅ Batch 12 geüpload (1000 rijen)\n",
      "  ✅ Batch 13 geüpload (1000 rijen)\n",
      "  ✅ Batch 14 geüpload (1000 rijen)\n",
      "  ✅ Batch 15 geüpload (1000 rijen)\n",
      "  ✅ Batch 16 geüpload (1000 rijen)\n",
      "  ✅ Batch 17 geüpload (1000 rijen)\n",
      "  ✅ Batch 18 geüpload (1000 rijen)\n",
      "  ✅ Batch 19 geüpload (1000 rijen)\n",
      "  ✅ Batch 20 geüpload (1000 rijen)\n",
      "  ✅ Batch 21 geüpload (1000 rijen)\n",
      "  ✅ Batch 22 geüpload (1000 rijen)\n",
      "  ✅ Batch 23 geüpload (1000 rijen)\n",
      "  ✅ Batch 24 geüpload (1000 rijen)\n",
      "  ✅ Batch 25 geüpload (1000 rijen)\n",
      "  ✅ Batch 26 geüpload (1000 rijen)\n",
      "  ✅ Batch 27 geüpload (1000 rijen)\n",
      "  ✅ Batch 28 geüpload (1000 rijen)\n",
      "  ✅ Batch 29 geüpload (1000 rijen)\n",
      "  ✅ Batch 30 geüpload (1000 rijen)\n",
      "  ✅ Batch 31 geüpload (1000 rijen)\n",
      "  ✅ Batch 32 geüpload (1000 rijen)\n",
      "  ✅ Batch 33 geüpload (1000 rijen)\n",
      "  ✅ Batch 34 geüpload (1000 rijen)\n",
      "  ✅ Batch 35 geüpload (1000 rijen)\n",
      "  ✅ Batch 36 geüpload (1000 rijen)\n",
      "  ✅ Batch 37 geüpload (1000 rijen)\n",
      "  ✅ Batch 38 geüpload (1000 rijen)\n",
      "  ✅ Batch 39 geüpload (1000 rijen)\n",
      "  ✅ Batch 40 geüpload (1000 rijen)\n",
      "  ✅ Batch 41 geüpload (1000 rijen)\n",
      "  ✅ Batch 42 geüpload (1000 rijen)\n",
      "  ✅ Batch 43 geüpload (1000 rijen)\n",
      "  ✅ Batch 44 geüpload (1000 rijen)\n",
      "  ✅ Batch 45 geüpload (1000 rijen)\n",
      "  ✅ Batch 46 geüpload (1000 rijen)\n",
      "  ✅ Batch 47 geüpload (1000 rijen)\n",
      "  ✅ Batch 48 geüpload (1000 rijen)\n",
      "  ✅ Batch 49 geüpload (1000 rijen)\n",
      "  ✅ Batch 50 geüpload (1000 rijen)\n",
      "  ✅ Batch 51 geüpload (1000 rijen)\n",
      "  ✅ Batch 52 geüpload (1000 rijen)\n",
      "  ✅ Batch 53 geüpload (1000 rijen)\n",
      "  ✅ Batch 54 geüpload (1000 rijen)\n",
      "  ✅ Batch 55 geüpload (1000 rijen)\n",
      "  ✅ Batch 56 geüpload (1000 rijen)\n",
      "  ✅ Batch 57 geüpload (1000 rijen)\n",
      "  ✅ Batch 58 geüpload (1000 rijen)\n",
      "  ✅ Batch 59 geüpload (1000 rijen)\n",
      "  ✅ Batch 60 geüpload (1000 rijen)\n",
      "  ✅ Batch 61 geüpload (1000 rijen)\n",
      "  ✅ Batch 62 geüpload (1000 rijen)\n",
      "  ✅ Batch 63 geüpload (1000 rijen)\n",
      "  ✅ Batch 64 geüpload (1000 rijen)\n",
      "  ✅ Batch 65 geüpload (1000 rijen)\n",
      "  ✅ Batch 66 geüpload (1000 rijen)\n",
      "  ✅ Batch 67 geüpload (1000 rijen)\n",
      "  ✅ Batch 68 geüpload (1000 rijen)\n",
      "  ✅ Batch 69 geüpload (1000 rijen)\n",
      "  ✅ Batch 70 geüpload (1000 rijen)\n",
      "  ✅ Batch 71 geüpload (1000 rijen)\n",
      "  ✅ Batch 72 geüpload (1000 rijen)\n",
      "  ✅ Batch 73 geüpload (1000 rijen)\n",
      "  ✅ Batch 74 geüpload (1000 rijen)\n",
      "  ✅ Batch 75 geüpload (1000 rijen)\n",
      "  ✅ Batch 76 geüpload (1000 rijen)\n",
      "  ✅ Batch 77 geüpload (1000 rijen)\n",
      "  ✅ Batch 78 geüpload (1000 rijen)\n",
      "  ✅ Batch 79 geüpload (1000 rijen)\n",
      "  ✅ Batch 80 geüpload (1000 rijen)\n",
      "  ✅ Batch 81 geüpload (1000 rijen)\n",
      "  ✅ Batch 82 geüpload (1000 rijen)\n",
      "  ✅ Batch 83 geüpload (1000 rijen)\n",
      "  ✅ Batch 84 geüpload (1000 rijen)\n",
      "  ✅ Batch 85 geüpload (1000 rijen)\n",
      "  ✅ Batch 86 geüpload (1000 rijen)\n",
      "  ✅ Batch 87 geüpload (1000 rijen)\n",
      "  ✅ Batch 88 geüpload (1000 rijen)\n",
      "  ✅ Batch 89 geüpload (1000 rijen)\n",
      "  ✅ Batch 90 geüpload (1000 rijen)\n",
      "  ✅ Batch 91 geüpload (1000 rijen)\n",
      "  ✅ Batch 92 geüpload (1000 rijen)\n",
      "  ✅ Batch 93 geüpload (1000 rijen)\n",
      "  ✅ Batch 94 geüpload (1000 rijen)\n",
      "  ✅ Batch 95 geüpload (1000 rijen)\n",
      "  ✅ Batch 96 geüpload (1000 rijen)\n",
      "  ✅ Batch 97 geüpload (1000 rijen)\n",
      "  ✅ Batch 98 geüpload (1000 rijen)\n",
      "  ✅ Batch 99 geüpload (1000 rijen)\n",
      "  ✅ Batch 100 geüpload (1000 rijen)\n",
      "  ✅ Batch 101 geüpload (1000 rijen)\n",
      "  ✅ Batch 102 geüpload (1000 rijen)\n",
      "  ✅ Batch 103 geüpload (1000 rijen)\n",
      "  ✅ Batch 104 geüpload (1000 rijen)\n",
      "  ✅ Batch 105 geüpload (1000 rijen)\n",
      "  ✅ Batch 106 geüpload (1000 rijen)\n",
      "  ✅ Batch 107 geüpload (1000 rijen)\n",
      "  ✅ Batch 108 geüpload (1000 rijen)\n",
      "  ✅ Batch 109 geüpload (1000 rijen)\n",
      "  ✅ Batch 110 geüpload (1000 rijen)\n",
      "  ✅ Batch 111 geüpload (1000 rijen)\n",
      "  ✅ Batch 112 geüpload (1000 rijen)\n",
      "  ✅ Batch 113 geüpload (1000 rijen)\n",
      "  ✅ Batch 114 geüpload (1000 rijen)\n",
      "  ✅ Batch 115 geüpload (1000 rijen)\n",
      "  ✅ Batch 116 geüpload (1000 rijen)\n",
      "  ✅ Batch 117 geüpload (1000 rijen)\n",
      "  ✅ Batch 118 geüpload (1000 rijen)\n",
      "  ✅ Batch 119 geüpload (1000 rijen)\n",
      "  ✅ Batch 120 geüpload (1000 rijen)\n",
      "  ✅ Batch 121 geüpload (1000 rijen)\n",
      "  ✅ Batch 122 geüpload (1000 rijen)\n",
      "  ✅ Batch 123 geüpload (1000 rijen)\n",
      "  ✅ Batch 124 geüpload (1000 rijen)\n",
      "  ✅ Batch 125 geüpload (575 rijen)\n",
      "\n",
      "⏳ Herinschakelen van FOREIGN KEY constraints...\n",
      "\n",
      "🎉 Upload voltooid voor alle tabellen!\n"
     ]
    }
   ],
   "source": [
    "def clean_nan_values(dw):\n",
    "    for table_name, df in dw.items():\n",
    "        # Zet alle NaN naar None zodat SQL Server NULL kan verwerken\n",
    "        dw[table_name] = df.astype(object).where(pd.notnull(df), None)\n",
    "    return dw\n",
    "\n",
    "# Pas toe op je dataWarehouse dictionary\n",
    "dfs_sourcedatamodel = clean_nan_values(dfs_sourcedatamodel)\n",
    "\n",
    "\n",
    "def upload_dataframes_to_sql(dw):\n",
    "    try:\n",
    "        with pyodbc.connect(connection_string2, autocommit=False) as conn:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.fast_executemany = True  # Maakt batch-inserts sneller\n",
    "            \n",
    "            print(\"⏳ Uitschakelen van FOREIGN KEY constraints...\")\n",
    "            cursor.execute(\"EXEC sp_MSforeachtable 'ALTER TABLE ? NOCHECK CONSTRAINT ALL'\")\n",
    "            conn.commit()\n",
    "            \n",
    "            # Loop over elke tabel\n",
    "            for table_name, df in dw.items():\n",
    "                print(f\"\\nBezig met uploaden van tabel: {table_name}...\")\n",
    "                \n",
    "                columns = ', '.join([f'[{col}]' for col in df.columns])\n",
    "                placeholders = ', '.join(['?'] * len(df.columns))\n",
    "                insert_query = f\"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})\"\n",
    "                \n",
    "                # Gebruik batch commit\n",
    "                batch_size = 1000\n",
    "                data_list = [tuple(row) for _, row in df.iterrows()]\n",
    "                \n",
    "                for i in range(0, len(data_list), batch_size):\n",
    "                    try:\n",
    "                        cursor.executemany(insert_query, data_list[i:i+batch_size])\n",
    "                        conn.commit()\n",
    "                        print(f\"  ✅ Batch {i//batch_size + 1} geüpload ({len(data_list[i:i+batch_size])} rijen)\")\n",
    "                    except pyodbc.Error as e:\n",
    "                        conn.rollback()\n",
    "                        print(f\"  ❌ Fout in batch {i//batch_size + 1}: {str(e)}\")\n",
    "                \n",
    "            print(\"\\n⏳ Herinschakelen van FOREIGN KEY constraints...\")\n",
    "            cursor.execute(\"EXEC sp_MSforeachtable 'ALTER TABLE ? CHECK CONSTRAINT ALL'\")\n",
    "            conn.commit()\n",
    "            \n",
    "            print(\"\\n🎉 Upload voltooid voor alle tabellen!\")\n",
    "            cursor.close()\n",
    "            \n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"❌ Databasefout: {e}\")\n",
    "\n",
    "upload_dataframes_to_sql(dfs_sourcedatamodel)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
